{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load various models from scikit-learn's library\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# also get some metrics to try\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfVectorizer\n",
    "\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec, LineSentence\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense, LSTM, GlobalAveragePooling1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import reuters\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data\n",
    "\n",
    "### IMDB reviews sentiment analysis\n",
    "\n",
    "This is a neural network ready dataset from [Keras](https://keras.io/datasets/#imdb-movie-reviews-sentiment-classification). The words in the dataset have already been converted into integer IDs, so you can't easily have a look at what's in there.\n",
    "\n",
    "This is a sentiment analysis or polarity dataset, which means that the target labels are positive or negative. It's a relatively simpler task for a ML model to solve.\n",
    "\n",
    "I'll be using dictionaries to store my data. After I've grabbed the data from keras, I join the integer IDs with spaces to make text for scikit-learn: scikit-learn's vectorizers expect strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data = {\"name\" : \"imdb\", \"ovr\" : False}\n",
    "(a, b), (c, d) = imdb.load_data(num_words=50000)\n",
    "imdb_data[\"X_train_ids\"], imdb_data[\"y_train\"], imdb_data[\"X_test_ids\"], imdb_data[\"y_test\"] = a, b, c, d\n",
    "\n",
    "# For scikit-learn to like the input data, it will needs strings\n",
    "imdb_data[\"X_train\"] = [\" \".join([str(x) for x in line]) for line in imdb_data[\"X_train_ids\"]]\n",
    "imdb_data[\"X_test\"] = [\" \".join([str(x) for x in line]) for line in imdb_data[\"X_test_ids\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a look at what we're dealing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations in training data: 25000; test data: 25000\n",
      "Min number of words per line in training set: 11\n",
      "Max number of words per line in training set: 2494\n",
      "Average number of words per line in training set: 238.71364\n",
      "Total vocabulary size: 49998\n"
     ]
    }
   ],
   "source": [
    "imdb_data[\"train_size\"], imdb_data[\"test_size\"] = len(imdb_data[\"X_train\"]), len(imdb_data[\"X_test\"])\n",
    "imdb_data[\"avg_length\"] = sum([len(i) for i in imdb_data[\"X_train_ids\"]])/len(imdb_data[\"X_train_ids\"])\n",
    "imdb_data[\"vocab_size\"] = len(set([i for j in imdb_data[\"X_train_ids\"] for i in j]))\n",
    "\n",
    "print(f\"Observations in training data: {imdb_data['train_size']}; test data: {imdb_data['test_size']}\")\n",
    "print(f\"Min number of words per line in training set: {min([len(i) for i in imdb_data['X_train_ids']])}\")\n",
    "print(f\"Max number of words per line in training set: {max([len(i) for i in imdb_data['X_train_ids']])}\")\n",
    "print(f\"Average number of words per line in training set: {imdb_data['avg_length']}\")\n",
    "print(f\"Total vocabulary size: {imdb_data['vocab_size']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A lot of baby names\n",
    "\n",
    "The US government has made available [baby names](https://catalog.data.gov/dataset/baby-names-from-social-security-card-applications-national-level-data) from social security card applications. These records go back to 1880 and also indicate the sex of the baby. I'll be trying to predict which names are male and which are female.\n",
    "\n",
    "Once you've extracted the files to a folder, the following Python code will join them all into a csv file.\n",
    "\n",
    "```\n",
    "import os\n",
    "import re\n",
    "\n",
    "with open(\"babies.csv\", \"w\") as w:\n",
    "    for f in [f for f in os.listdir(os.getcwd()) if \"txt\" in str(f)]:\n",
    "        with open(f) as f:\n",
    "            year = re.search(r'[\\d]{4}', f.name)[0]\n",
    "            for line in f:\n",
    "                w.write(year+\",\"+line)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What I want to do is sort the names by year, remove all duplicates, and then split older and newer names into the training and test sets, respectively. This way, my machine learning task is correctly inferring the gender of newer names only having seen older ones.\n",
    "\n",
    "Below you can see a sample of a few names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1880,Mary,F,7065\\n', '1880,Anna,F,2604\\n', '1880,Emma,F,2003\\n', '1880,Elizabeth,F,1939\\n', '1880,Minnie,F,1746\\n']\n"
     ]
    }
   ],
   "source": [
    "with open(\"babies.csv\") as f:\n",
    "    baby_list = f.readlines()\n",
    "\n",
    "# Sort by first 4 characters, the year\n",
    "baby_list.sort(key=lambda x: x[:4])\n",
    "\n",
    "print(baby_list[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What I'm going to do is keep every combination of name and sex in a `set()`. Python sets do not keep duplicates and are very fast at `if x in y` operations, making them perfect for this work. With the names properly organized, it's easy to keep 20,000 for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "baby_set = set()\n",
    "unique_baby_list = []\n",
    "\n",
    "for baby in baby_list:\n",
    "    if \" \".join(baby.split(\",\")[1:3]) in baby_set:\n",
    "        pass\n",
    "    else:\n",
    "        baby_set.add(\" \".join(baby.split(\",\")[1:3]))\n",
    "        unique_baby_list.append(baby)\n",
    "\n",
    "# Pick test set\n",
    "baby_train = unique_baby_list[:-20000]\n",
    "baby_test = unique_baby_list[-20000:]\n",
    "\n",
    "baby_data = {\"name\" : \"baby\", \"ovr\" : False}\n",
    "baby_data[\"X_train\"] = [baby.split(\",\")[1] for baby in baby_train]\n",
    "baby_data[\"X_test\"] = [baby.split(\",\")[1] for baby in baby_test]\n",
    "baby_data[\"y_train\"] = [baby.split(\",\")[2] == \"M\" for baby in baby_train]\n",
    "baby_data[\"y_test\"] = [baby.split(\",\")[2] == \"M\" for baby in baby_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data is split by character, we have a small vocabulary size. Even with the removal of duplicates, we still have 100,000+ records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations in training data: 87973; test data: 20000\n",
      "Min number of words per line in training set: 2\n",
      "Max number of words per line in training set: 15\n",
      "Average number of characters per name in training set: 6.442374364861946\n",
      "Total character vocabulary size: 52\n"
     ]
    }
   ],
   "source": [
    "baby_data[\"train_size\"], baby_data[\"test_size\"] = len(baby_data[\"X_train\"]), len(baby_data[\"X_test\"])\n",
    "baby_data[\"avg_length\"] = sum([len(i) for i in baby_data[\"X_train\"]])/len(baby_data[\"X_train\"])\n",
    "baby_data[\"vocab_size\"] = len(set([i for j in baby_data[\"X_train\"] for i in j]))\n",
    "\n",
    "print(f\"Observations in training data: {baby_data['train_size']}; test data: {len(baby_data['X_test'])}\")\n",
    "print(f\"Min number of words per line in training set: {min([len(i) for i in baby_data['X_train']])}\")\n",
    "print(f\"Max number of words per line in training set: {max([len(i) for i in baby_data['X_train']])}\")\n",
    "print(f\"Average number of characters per name in training set: {baby_data['avg_length']}\")\n",
    "print(f\"Total character vocabulary size: {baby_data['vocab_size']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Newsgroup posts\n",
    "\n",
    "These are categorized newsgroup posts you can get [from scikit-learn](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html) ([user guide](scikit-learn.org/stable/datasets/twenty_newsgroups.html). These are rather long and varied texts drawn from 18,000 posts. Each of these belong in a different topic. You can read a bit more about the dataset [here](http://qwone.com/~jason/20Newsgroups/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng_train_raw = fetch_20newsgroups(subset=\"train\", remove=(\"headers\", \"footers\", \"quotes\"))\n",
    "ng_test_raw = fetch_20newsgroups(subset=\"test\", remove=(\"headers\", \"footers\", \"quotes\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a scikit-learn datasource, there are extras you can play with. For example, the target labels can be accessed this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "print(ng_train_raw.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example post looks lie this. As you can see, these are multiple sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n"
     ]
    }
   ],
   "source": [
    "print(ng_train_raw.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng_data = {\"name\" : \"newsgroup20\", \"ovr\" : False}\n",
    "ng_data.update({\"X_train\" : ng_train_raw.data, \"y_train\" : ng_train_raw.target})\n",
    "ng_data.update({\"X_test\" : ng_test_raw.data, \"y_test\" : ng_test_raw.target})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average these posts are shorter than the imdb reviews; however, there are some monster posts lurking in there.\n",
    "\n",
    "The total vocabulary size of the newsgroup set is **much higher** than the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations in training data: 11314; test data: 7532\n",
      "Min number of words per line in training set: 1\n",
      "Max number of words per line in training set: 20083\n",
      "Average number of words per line in training set: 206.15980201520242\n",
      "Total vocabulary size: 282099\n"
     ]
    }
   ],
   "source": [
    "ng_data[\"train_size\"], ng_data[\"test_size\"] = len(ng_data[\"X_train\"]), len(ng_data[\"X_test\"])\n",
    "ng_data[\"avg_length\"] = sum([len(i.split(' ')) for i in ng_data[\"X_train\"]])/len(ng_data[\"X_train\"])\n",
    "ng_data[\"vocab_size\"] = len(set([i.lower() for j in ng_data[\"X_train\"] for i in j.split(\" \")]))\n",
    "\n",
    "print(f\"Observations in training data: {len(ng_data['X_train'])}; test data: {len(ng_data['X_test'])}\")\n",
    "print(f\"Min number of words per line in training set: {min([len(i.split(' ')) for i in ng_data['X_train']])}\")\n",
    "print(f\"Max number of words per line in training set: {max([len(i.split(' ')) for i in ng_data['X_train']])}\")\n",
    "print(f\"Average number of words per line in training set: {ng_data['avg_length']}\")\n",
    "print(f\"Total vocabulary size: {ng_data['vocab_size']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reuters newswire dataset\n",
    "\n",
    "The Reuters dataset is a collection of short categorized news stories. I followed [Martin Thoma's blog post to get started](https://martin-thoma.com/nlp-reuters/).\n",
    "\n",
    "We're usign the nltk version of the dataset, but I'm not sure what that is exactly. Our dataset has 14333 records, but the more popular [reuters-21578](https://archive.ics.uci.edu/ml/datasets/reuters-21578+text+categorization+collection) has 21578. Since that dataset was collected from 1987 newswire texts, I assume the one we're using is similar.\n",
    "\n",
    "To get a copy of the Reuters data, you have to use `nltk.download(\"reuters\")`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_reuters():\n",
    "    reuters_data = {\"name\" : \"reuters\", \"ovr\" : True}\n",
    "    \n",
    "    # The test and train sets are listed as IDs in the .fileids() member\n",
    "    train_ids = list(filter(lambda x: x[:5] == \"train\", reuters.fileids()))\n",
    "    test_ids = list(filter(lambda x: x[:4] == \"test\", reuters.fileids()))\n",
    "    reuters_data[\"X_train\"] = list(map(lambda x: reuters.raw(x), train_ids))\n",
    "    reuters_data[\"X_test\"] = list(map(lambda x: reuters.raw(x), test_ids))\n",
    "    \n",
    "    # The MultiLabelBinarizer will get you the 1s and 0s your model wants\n",
    "    mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "    reuters_data[\"y_train\"] = mlb.fit_transform(list(map(lambda x: reuters.categories(x), train_ids)))\n",
    "    reuters_data[\"y_test\"] = mlb.transform(list(map(lambda x: reuters.categories(x), test_ids)))\n",
    "    \n",
    "    return reuters_data\n",
    "    \n",
    "reuters_data = load_reuters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main challenge with the Reuters dataset are its large amount of classes and their multi-label nature. Models have to cope with these news items belonging to more than one category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example observation targets: ['corn', 'grain', 'rice', 'rubber', 'sugar', 'tin', 'trade']\n",
      "Number of classes: 90\n",
      "['acq', 'alum', 'barley', 'bop', 'carcass', 'castor-oil', 'cocoa', 'coconut', 'coconut-oil', 'coffee', 'copper', 'copra-cake', 'corn', 'cotton', 'cotton-oil', 'cpi', 'cpu', 'crude', 'dfl', 'dlr', 'dmk', 'earn', 'fuel', 'gas', 'gnp', 'gold', 'grain', 'groundnut', 'groundnut-oil', 'heat', 'hog', 'housing', 'income', 'instal-debt', 'interest', 'ipi', 'iron-steel', 'jet', 'jobs', 'l-cattle', 'lead', 'lei', 'lin-oil', 'livestock', 'lumber', 'meal-feed', 'money-fx', 'money-supply', 'naphtha', 'nat-gas', 'nickel', 'nkr', 'nzdlr', 'oat', 'oilseed', 'orange', 'palladium', 'palm-oil', 'palmkernel', 'pet-chem', 'platinum', 'potato', 'propane', 'rand', 'rape-oil', 'rapeseed', 'reserves', 'retail', 'rice', 'rubber', 'rye', 'ship', 'silver', 'sorghum', 'soy-meal', 'soy-oil', 'soybean', 'strategic-metal', 'sugar', 'sun-meal', 'sun-oil', 'sunseed', 'tea', 'tin', 'trade', 'veg-oil', 'wheat', 'wpi', 'yen', 'zinc']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Example observation targets: {reuters.categories('test/14832')}\")\n",
    "print(f\"Number of classes: {len(reuters.categories())}\")\n",
    "print(reuters.categories())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the observations only have one label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min number of target labels: 1\n",
      "Min number of target labels: 15\n",
      "Average number of target labels per observation: 1.235446792732666\n"
     ]
    }
   ],
   "source": [
    "print(f\"Min number of target labels: {min([len(reuters.categories(i)) for i in reuters.fileids()])}\")\n",
    "print(f\"Min number of target labels: {max([len(reuters.categories(i)) for i in reuters.fileids()])}\")\n",
    "print(f\"Average number of target labels per observation: {sum([len(reuters.categories(i)) for i in reuters.fileids()])/len(reuters.fileids())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the stats below aren't as high as imdb and newsgroup20, the models will take longer to do the multi-label. I use an `ovr` flag to tell scikit-learn to treat this dataset as a one-vs-rest problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations in training data: 11314; test data: 3019\n",
      "Min number of words per line in training set: 3\n",
      "Max number of words per line in training set: 1571\n",
      "Average number of words per line in training set: 166.21688763032566\n",
      "Total vocabulary size: 70000\n"
     ]
    }
   ],
   "source": [
    "reuters_data[\"train_size\"], reuters_data[\"test_size\"] = len(reuters_data[\"X_train\"]), len(reuters_data[\"X_test\"])\n",
    "reuters_data[\"avg_length\"] = sum([len(i.split(' ')) for i in reuters_data[\"X_train\"]])/len(reuters_data[\"X_train\"])\n",
    "reuters_data[\"vocab_size\"] = len(set([i.lower() for j in reuters_data[\"X_train\"] for i in j.split(\" \")]))\n",
    "\n",
    "print(f\"Observations in training data: {len(ng_data['X_train'])}; test data: {len(reuters_data['X_test'])}\")\n",
    "print(f\"Min number of words per line in training set: {min([len(i.split(' ')) for i in reuters_data['X_train']])}\")\n",
    "print(f\"Max number of words per line in training set: {max([len(i.split(' ')) for i in reuters_data['X_train']])}\")\n",
    "print(f\"Average number of words per line in training set: {sum([len(i.split(' ')) for i in reuters_data['X_train']])/len(reuters_data['X_train'])}\")\n",
    "print(f\"Total vocabulary size: {len(set([i.lower() for j in reuters_data['X_train'] for i in j.split(' ')]))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convenience functions\n",
    "\n",
    "Whenever we want to train on our datasets, we'll have to pre-process them and then train a bunch of different models on them. To do these things I've written some simple functions.\n",
    "\n",
    "The `vectorize()` functions expects one of scikit-learn's [vectorizers](http://scikit-learn.org/stable/modules/feature_extraction.html) as its first argument, and then vectorizes the two datasets it's given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(vectorizer, x_train, x_test=None):\n",
    "    train_vec = vectorizer.fit_transform(x_train)\n",
    "    if x_test:\n",
    "        test_vec = vectorizer.transform(x_test)\n",
    "    else:\n",
    "        test_vec = None\n",
    "    return train_vec, test_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `model_eval()` function iterates over models and datasets, training and evaluating each one. I had originally included more classification metrics, but I found that evaluating test sets so often can take up a lot of time. I'll stick with test accuracy as my main score.\n",
    "\n",
    "When you wrap a model in the [`OneVsRestClassifier()`](http://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html) function, it'll be re-run for each label separately. This makes training take a lot more time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def models_eval(models, datasets, train_key=\"X_train_vec\", test_key=\"X_test_vec\"):\n",
    "    for dataset in datasets:\n",
    "        print(f\"{dataset['name']:20} train/test {dataset['train_size']}/{dataset['test_size']} total vocab {dataset['vocab_size']}\")\n",
    "        print(f\"{20*' '}{57*'-'}\")\n",
    "        results = []\n",
    "        for name, model in models.items():\n",
    "            if dataset[\"ovr\"]: model = OneVsRestClassifier(model)\n",
    "            timer = timeit.default_timer()\n",
    "            model.fit(dataset[train_key], dataset[\"y_train\"])\n",
    "            train_elapsed = timeit.default_timer() - timer\n",
    "            timer = timeit.default_timer()\n",
    "            train_acc = accuracy_score(y_true = dataset[\"y_train\"], y_pred = model.predict(X=dataset[train_key]))\n",
    "            test_acc = accuracy_score(y_true = dataset[\"y_test\"], y_pred = model.predict(X=dataset[test_key]))\n",
    "            eval_elapsed = timeit.default_timer() - timer\n",
    "            results.append({\n",
    "                \"name\" : name, \n",
    "                \"model\" : model, \n",
    "                \"train_acc\" : train_acc, \n",
    "                \"test_acc\" : test_acc, \n",
    "                \"train_elapsed\" : train_elapsed, \n",
    "                \"eval_elapsed\" : eval_elapsed\n",
    "                })\n",
    "        results.sort(key=lambda x: -x[\"test_acc\"])\n",
    "        for result in results:\n",
    "            print(\"{:>19} | TRAIN {:5.1f}s | EVAL {:5.1f}s | TRAIN/TEST acc {:4.2f}/{:4.2f} |\".format(\n",
    "                result[\"name\"], \n",
    "                result[\"train_elapsed\"], \n",
    "                result[\"eval_elapsed\"], \n",
    "                result[\"train_acc\"], \n",
    "                result[\"test_acc\"]\n",
    "            ))\n",
    "        print(20*\" \"+57*\"-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text classification with basic vectorization\n",
    "\n",
    "We will start off out adventure with the easy-to-use [vectorizers](http://scikit-learn.org/stable/modules/feature_extraction.html) in scikit-learn. Without much effort these will give good results, which shows how useful a well-organized library like scikit-learn is.\n",
    "\n",
    "My choice of models comes down to whatever will run reasonably fast. I learned about LogisticRegression's `C=` parameter from [Martin Thoma's blog post](https://martin-thoma.com/nlp-reuters/). It's a parameter that's easy to miss in the [scikit-learn documentation](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html), but it sometimes gives really nice results.\n",
    "\n",
    "As I'm starting with word-based vectorization, I won't use the `baby` dataset just yet. I'll need character-level vectorization for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_models = {\"Logistic\" : LogisticRegression(solver=\"lbfgs\", n_jobs = -1), \n",
    "                  \"Logistic C=1000\" : LogisticRegression(solver=\"lbfgs\", n_jobs = -1, C=1000), \n",
    "                  \"RandomForest 10\" : RandomForestClassifier(n_jobs = -1), \n",
    "                  \"RandomForest 100\" : RandomForestClassifier(n_jobs = -1, n_estimators=100), \n",
    "                  \"RndForest 100 MD25\" : RandomForestClassifier(n_jobs = -1, n_estimators=100, max_depth=25), \n",
    "                  \"DecisionTree\" : DecisionTreeClassifier(), \n",
    "                  \"DecisionTree MD25\" : DecisionTreeClassifier(max_depth=25), \n",
    "                  \"MultinomialNB\":MultinomialNB()\n",
    "                 }\n",
    "\n",
    "list_of_datasets = [imdb_data, ng_data, reuters_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The simplest bag of words\n",
    "\n",
    "We'll start with the most simple. If a word is present, it gets a 1; otherwise it gets a 0.\n",
    "\n",
    "Whenever we test for words and flag them to the models, we're using a technique called \"bag of words\". Even if we're identifiying short sequences of words, like the presence of \"not good\" or \"red meat\", it's still bag of words, or maybe called bag of n-grams. The common alternative is modelling the sequence of words directly, as a kind of time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imdb                 train/test 25000/25000 total vocab 49998\n",
      "                    ---------------------------------------------------------\n",
      "           Logistic | TRAIN   1.8s | EVAL   0.0s | TRAIN/TEST acc 1.00/0.87 |\n",
      "    Logistic C=1000 | TRAIN   1.7s | EVAL   0.0s | TRAIN/TEST acc 1.00/0.86 |\n",
      "   RandomForest 100 | TRAIN  12.0s | EVAL   1.1s | TRAIN/TEST acc 1.00/0.85 |\n",
      " RndForest 100 MD25 | TRAIN   2.3s | EVAL   0.9s | TRAIN/TEST acc 0.95/0.84 |\n",
      "      MultinomialNB | TRAIN   0.0s | EVAL   0.0s | TRAIN/TEST acc 0.90/0.83 |\n",
      "    RandomForest 10 | TRAIN   1.5s | EVAL   0.2s | TRAIN/TEST acc 0.99/0.75 |\n",
      "  DecisionTree MD25 | TRAIN  10.8s | EVAL   0.0s | TRAIN/TEST acc 0.89/0.73 |\n",
      "       DecisionTree | TRAIN  23.7s | EVAL   0.0s | TRAIN/TEST acc 1.00/0.71 |\n",
      "                    ---------------------------------------------------------\n",
      "newsgroup20          train/test 11314/7532 total vocab 282099\n",
      "                    ---------------------------------------------------------\n",
      "           Logistic | TRAIN  14.1s | EVAL   0.0s | TRAIN/TEST acc 0.97/0.62 |\n",
      "      MultinomialNB | TRAIN   0.0s | EVAL   0.0s | TRAIN/TEST acc 0.81/0.62 |\n",
      "   RandomForest 100 | TRAIN   7.3s | EVAL   1.3s | TRAIN/TEST acc 0.97/0.60 |\n",
      "    Logistic C=1000 | TRAIN  17.8s | EVAL   0.0s | TRAIN/TEST acc 0.97/0.59 |\n",
      " RndForest 100 MD25 | TRAIN   0.7s | EVAL   1.0s | TRAIN/TEST acc 0.77/0.57 |\n",
      "    RandomForest 10 | TRAIN   1.0s | EVAL   0.4s | TRAIN/TEST acc 0.97/0.44 |\n",
      "       DecisionTree | TRAIN   6.5s | EVAL   0.0s | TRAIN/TEST acc 0.97/0.41 |\n",
      "  DecisionTree MD25 | TRAIN   1.7s | EVAL   0.0s | TRAIN/TEST acc 0.41/0.29 |\n",
      "                    ---------------------------------------------------------\n",
      "reuters              train/test 7769/3019 total vocab 70000\n",
      "                    ---------------------------------------------------------\n",
      "    Logistic C=1000 | TRAIN  41.6s | EVAL   0.1s | TRAIN/TEST acc 1.00/0.75 |\n",
      "           Logistic | TRAIN  39.2s | EVAL   0.1s | TRAIN/TEST acc 0.99/0.74 |\n",
      "       DecisionTree | TRAIN   6.8s | EVAL   0.2s | TRAIN/TEST acc 0.99/0.70 |\n",
      "  DecisionTree MD25 | TRAIN   6.0s | EVAL   0.3s | TRAIN/TEST acc 0.97/0.69 |\n",
      "      MultinomialNB | TRAIN   0.3s | EVAL   0.3s | TRAIN/TEST acc 0.68/0.66 |\n",
      "   RandomForest 100 | TRAIN  28.3s | EVAL  27.5s | TRAIN/TEST acc 1.00/0.64 |\n",
      "    RandomForest 10 | TRAIN  11.0s | EVAL  18.5s | TRAIN/TEST acc 0.95/0.60 |\n",
      " RndForest 100 MD25 | TRAIN  24.2s | EVAL  26.4s | TRAIN/TEST acc 0.83/0.55 |\n",
      "                    ---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for dataset in list_of_datasets:\n",
    "    dataset[\"X_train_vec\"], dataset[\"X_test_vec\"] = vectorize(CountVectorizer(max_features=50000, binary=True), dataset[\"X_train\"], dataset[\"X_test\"])\n",
    "\n",
    "models_eval(list_of_models, list_of_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tdidf with unigrams\n",
    "\n",
    "Here is a better approach: the [Term Document Inverser Document Frequency (TD-IDF) vectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html). This vectorizer will count word occurences in a sentence (or \"document\") but then divide these counts with how frequent each word appears in general. For example, if *aardvark* appears once in a sentence and once in the entire corpus, it gets a count of 1; however, if *and* appears once in a sentence but 10,000 times in the corpus, it gets a TD-IDF count of 0.0001. Normalizes your data in a way that gives an edge to rarer words but a penalty to more common words.\n",
    "\n",
    "According to [this Wikipedia article](https://en.wikipedia.org/wiki/Tf%E2%80%93idf), 83% of text classification tasks use TD-IDF.\n",
    "\n",
    "Anyways, I'll keep setting the maximum vocabulary size to 50,000 to make of these examples roughly comparable. Increasing the maximum vocabulary usually increases model accuracy. When scikit-learn is given a max vocabulary size, it'll only keep the most frequent words.\n",
    "\n",
    "We should get **89%** for imdb, **68%** for newsgroup20, and **80%** for reuters. These are the amounts we'll try to beat afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imdb                 train/test 25000/25000 total vocab 49998\n",
      "                    ---------------------------------------------------------\n",
      "           Logistic | TRAIN   1.2s | EVAL   0.0s | TRAIN/TEST acc 0.94/0.89 |\n",
      "    Logistic C=1000 | TRAIN   1.7s | EVAL   0.0s | TRAIN/TEST acc 1.00/0.87 |\n",
      "   RandomForest 100 | TRAIN  10.3s | EVAL   1.1s | TRAIN/TEST acc 1.00/0.84 |\n",
      " RndForest 100 MD25 | TRAIN   2.5s | EVAL   0.9s | TRAIN/TEST acc 0.96/0.83 |\n",
      "      MultinomialNB | TRAIN   0.0s | EVAL   0.0s | TRAIN/TEST acc 0.91/0.83 |\n",
      "    RandomForest 10 | TRAIN   1.4s | EVAL   0.5s | TRAIN/TEST acc 0.99/0.74 |\n",
      "  DecisionTree MD25 | TRAIN  13.1s | EVAL   0.0s | TRAIN/TEST acc 0.91/0.72 |\n",
      "       DecisionTree | TRAIN  24.6s | EVAL   0.0s | TRAIN/TEST acc 1.00/0.71 |\n",
      "                    ---------------------------------------------------------\n",
      "newsgroup20          train/test 11314/7532 total vocab 282099\n",
      "                    ---------------------------------------------------------\n",
      "    Logistic C=1000 | TRAIN  17.7s | EVAL   0.0s | TRAIN/TEST acc 0.97/0.68 |\n",
      "           Logistic | TRAIN   7.5s | EVAL   0.0s | TRAIN/TEST acc 0.89/0.68 |\n",
      "      MultinomialNB | TRAIN   0.0s | EVAL   0.0s | TRAIN/TEST acc 0.81/0.62 |\n",
      "   RandomForest 100 | TRAIN   6.9s | EVAL   1.3s | TRAIN/TEST acc 0.97/0.60 |\n",
      " RndForest 100 MD25 | TRAIN   0.8s | EVAL   1.1s | TRAIN/TEST acc 0.80/0.57 |\n",
      "    RandomForest 10 | TRAIN   0.9s | EVAL   0.3s | TRAIN/TEST acc 0.97/0.45 |\n",
      "       DecisionTree | TRAIN   8.8s | EVAL   0.0s | TRAIN/TEST acc 0.97/0.40 |\n",
      "  DecisionTree MD25 | TRAIN   2.9s | EVAL   0.0s | TRAIN/TEST acc 0.41/0.28 |\n",
      "                    ---------------------------------------------------------\n",
      "reuters              train/test 7769/3019 total vocab 70000\n",
      "                    ---------------------------------------------------------\n",
      "    Logistic C=1000 | TRAIN  45.2s | EVAL   0.1s | TRAIN/TEST acc 1.00/0.80 |\n",
      "       DecisionTree | TRAIN  24.7s | EVAL   0.2s | TRAIN/TEST acc 0.99/0.70 |\n",
      "  DecisionTree MD25 | TRAIN  21.6s | EVAL   0.2s | TRAIN/TEST acc 0.98/0.69 |\n",
      "           Logistic | TRAIN  33.8s | EVAL   0.1s | TRAIN/TEST acc 0.72/0.67 |\n",
      "   RandomForest 100 | TRAIN  29.8s | EVAL  25.6s | TRAIN/TEST acc 0.99/0.64 |\n",
      "    RandomForest 10 | TRAIN  10.9s | EVAL  18.5s | TRAIN/TEST acc 0.93/0.60 |\n",
      " RndForest 100 MD25 | TRAIN  26.4s | EVAL  26.8s | TRAIN/TEST acc 0.84/0.55 |\n",
      "      MultinomialNB | TRAIN   0.3s | EVAL   0.3s | TRAIN/TEST acc 0.45/0.41 |\n",
      "                    ---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for dataset in list_of_datasets:\n",
    "    dataset[\"X_train_vec\"], dataset[\"X_test_vec\"] = vectorize(TfidfVectorizer(max_features=50000), dataset[\"X_train\"], dataset[\"X_test\"])\n",
    "\n",
    "models_eval(list_of_models, list_of_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tdidf with bigrams\n",
    "\n",
    "We can help the models by informing them of some short word sequences, say sequences of two: these are called bi-grams. For example the imdb models will get a bit of extra help by knowing the presence of \"not good\" instead of only \"not\" and \"good\" separately; this helps in the sentiment analysis task.\n",
    "\n",
    "We get slight decreases with **90%** for imdb, **67%** for newsgroup20, and **79%** for reuters. Some rarer words are important to the models, and they're being pushed out by more common bi-grams. Increasing the `max_features` to 75,000 doesn't make a lot of difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imdb                 train/test 25000/25000 total vocab 49998\n",
      "                    ---------------------------------------------------------\n",
      "           Logistic | TRAIN   2.3s | EVAL   0.0s | TRAIN/TEST acc 0.95/0.90 |\n",
      "    Logistic C=1000 | TRAIN   2.5s | EVAL   0.0s | TRAIN/TEST acc 1.00/0.89 |\n",
      "      MultinomialNB | TRAIN   0.0s | EVAL   0.0s | TRAIN/TEST acc 0.92/0.88 |\n",
      "   RandomForest 100 | TRAIN  12.1s | EVAL   1.5s | TRAIN/TEST acc 1.00/0.85 |\n",
      " RndForest 100 MD25 | TRAIN   2.9s | EVAL   1.3s | TRAIN/TEST acc 0.96/0.85 |\n",
      "    RandomForest 10 | TRAIN   1.6s | EVAL   0.6s | TRAIN/TEST acc 0.99/0.76 |\n",
      "  DecisionTree MD25 | TRAIN  20.0s | EVAL   0.0s | TRAIN/TEST acc 0.91/0.72 |\n",
      "       DecisionTree | TRAIN  36.8s | EVAL   0.0s | TRAIN/TEST acc 1.00/0.71 |\n",
      "                    ---------------------------------------------------------\n",
      "newsgroup20          train/test 11314/7532 total vocab 282099\n",
      "                    ---------------------------------------------------------\n",
      "    Logistic C=1000 | TRAIN  23.8s | EVAL   0.1s | TRAIN/TEST acc 0.97/0.67 |\n",
      "           Logistic | TRAIN   9.8s | EVAL   0.0s | TRAIN/TEST acc 0.91/0.66 |\n",
      "      MultinomialNB | TRAIN   0.0s | EVAL   0.1s | TRAIN/TEST acc 0.85/0.61 |\n",
      "   RandomForest 100 | TRAIN   8.0s | EVAL   1.6s | TRAIN/TEST acc 0.97/0.59 |\n",
      " RndForest 100 MD25 | TRAIN   0.9s | EVAL   1.2s | TRAIN/TEST acc 0.78/0.56 |\n",
      "    RandomForest 10 | TRAIN   1.1s | EVAL   0.5s | TRAIN/TEST acc 0.97/0.45 |\n",
      "       DecisionTree | TRAIN  13.3s | EVAL   0.0s | TRAIN/TEST acc 0.97/0.40 |\n",
      "  DecisionTree MD25 | TRAIN   4.5s | EVAL   0.0s | TRAIN/TEST acc 0.40/0.28 |\n",
      "                    ---------------------------------------------------------\n",
      "reuters              train/test 7769/3019 total vocab 70000\n",
      "                    ---------------------------------------------------------\n",
      "    Logistic C=1000 | TRAIN  62.5s | EVAL   0.2s | TRAIN/TEST acc 1.00/0.79 |\n",
      "  DecisionTree MD25 | TRAIN  37.5s | EVAL   0.5s | TRAIN/TEST acc 0.98/0.71 |\n",
      "       DecisionTree | TRAIN  41.2s | EVAL   0.5s | TRAIN/TEST acc 0.99/0.70 |\n",
      "   RandomForest 100 | TRAIN  36.2s | EVAL  40.6s | TRAIN/TEST acc 0.99/0.68 |\n",
      "           Logistic | TRAIN  42.3s | EVAL   0.2s | TRAIN/TEST acc 0.68/0.64 |\n",
      "    RandomForest 10 | TRAIN  12.8s | EVAL  18.7s | TRAIN/TEST acc 0.95/0.64 |\n",
      " RndForest 100 MD25 | TRAIN  29.4s | EVAL  43.4s | TRAIN/TEST acc 0.85/0.59 |\n",
      "      MultinomialNB | TRAIN   0.5s | EVAL   0.5s | TRAIN/TEST acc 0.54/0.53 |\n",
      "                    ---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for dataset in list_of_datasets:\n",
    "    dataset[\"X_train_vec\"], dataset[\"X_test_vec\"] = vectorize(TfidfVectorizer(max_features=50000, ngram_range = [1, 2]), dataset[\"X_train\"], dataset[\"X_test\"])\n",
    "\n",
    "models_eval(list_of_models, list_of_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing\n",
    "\n",
    "Before we move on to other things, we can try pre-processing our text data further. I got the lemmatization code [here](http://scikit-learn.org/stable/modules/feature_extraction.html#customizing-the-vectorizer-classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can see that this beats the best we had so far. It won't work with the imdb set. With 75,000 and 1,2 ngrams we get **67%** for newsgroup20 and **80%** for reuters. With only 1,1, we **81%** for reuters, which is out best so far. Newsgroup20 gets **66%**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_datasets = [ng_data, reuters_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newsgroup20          train/test 11314/7532 total vocab 282099\n",
      "                    ---------------------------------------------------------\n",
      "    Logistic C=1000 | TRAIN  19.8s | EVAL   0.0s | TRAIN/TEST acc 0.97/0.66 |\n",
      "           Logistic | TRAIN   8.5s | EVAL   0.0s | TRAIN/TEST acc 0.88/0.64 |\n",
      "      MultinomialNB | TRAIN   0.0s | EVAL   0.0s | TRAIN/TEST acc 0.83/0.62 |\n",
      "   RandomForest 100 | TRAIN   7.3s | EVAL   1.4s | TRAIN/TEST acc 0.97/0.60 |\n",
      " RndForest 100 MD25 | TRAIN   0.7s | EVAL   0.9s | TRAIN/TEST acc 0.76/0.56 |\n",
      "    RandomForest 10 | TRAIN   1.0s | EVAL   0.4s | TRAIN/TEST acc 0.97/0.49 |\n",
      "       DecisionTree | TRAIN   9.2s | EVAL   0.0s | TRAIN/TEST acc 0.97/0.42 |\n",
      "  DecisionTree MD25 | TRAIN   3.3s | EVAL   0.0s | TRAIN/TEST acc 0.46/0.31 |\n",
      "                    ---------------------------------------------------------\n",
      "reuters              train/test 7769/3019 total vocab 70000\n",
      "                    ---------------------------------------------------------\n",
      "    Logistic C=1000 | TRAIN  60.6s | EVAL   0.1s | TRAIN/TEST acc 0.99/0.81 |\n",
      "  DecisionTree MD25 | TRAIN  26.5s | EVAL   0.4s | TRAIN/TEST acc 0.98/0.72 |\n",
      "       DecisionTree | TRAIN  30.5s | EVAL   0.4s | TRAIN/TEST acc 0.99/0.72 |\n",
      "   RandomForest 100 | TRAIN  36.1s | EVAL  37.2s | TRAIN/TEST acc 0.99/0.69 |\n",
      "           Logistic | TRAIN  44.7s | EVAL   0.1s | TRAIN/TEST acc 0.70/0.66 |\n",
      "    RandomForest 10 | TRAIN  12.0s | EVAL  18.6s | TRAIN/TEST acc 0.95/0.64 |\n",
      " RndForest 100 MD25 | TRAIN  28.9s | EVAL  37.4s | TRAIN/TEST acc 0.84/0.59 |\n",
      "      MultinomialNB | TRAIN   0.4s | EVAL   0.4s | TRAIN/TEST acc 0.55/0.52 |\n",
      "                    ---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for dataset in list_of_datasets:\n",
    "    dataset[\"X_train_vec\"], dataset[\"X_test_vec\"] = vectorize(TfidfVectorizer(max_features=50000, ngram_range = [1, 2], \n",
    "                                                                              tokenizer=LemmaTokenizer(), stop_words=\"english\"), \n",
    "                                                              dataset[\"X_train\"], dataset[\"X_test\"])\n",
    "\n",
    "models_eval(list_of_models, list_of_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hashing trick with character ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_models = {\"Logistic\" : LogisticRegression(solver=\"lbfgs\", n_jobs = -1), \n",
    "                  \"Logistic C=1000\" : LogisticRegression(solver=\"lbfgs\", n_jobs = -1, C=1000), \n",
    "                  \"RandomForest 10\" : RandomForestClassifier(n_jobs = -1)\n",
    "                 }\n",
    "\n",
    "list_of_datasets = [imdb_data, baby_data, ng_data, reuters_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imdb                 train/test 25000/25000 total vocab 49998\n",
      "                    ---------------------------------------------------------\n",
      "    Logistic C=1000 | TRAIN   7.0s | EVAL   0.1s | TRAIN/TEST acc 0.90/0.86 |\n",
      "           Logistic | TRAIN   6.0s | EVAL   0.1s | TRAIN/TEST acc 0.81/0.80 |\n",
      "    RandomForest 10 | TRAIN   2.6s | EVAL   0.7s | TRAIN/TEST acc 0.99/0.69 |\n",
      "                    ---------------------------------------------------------\n",
      "baby                 train/test 87973/20000 total vocab 52\n",
      "                    ---------------------------------------------------------\n",
      "           Logistic | TRAIN   1.9s | EVAL   0.0s | TRAIN/TEST acc 0.85/0.81 |\n",
      "    Logistic C=1000 | TRAIN   1.9s | EVAL   0.0s | TRAIN/TEST acc 0.87/0.79 |\n",
      "    RandomForest 10 | TRAIN  84.5s | EVAL   0.6s | TRAIN/TEST acc 0.90/0.78 |\n",
      "                    ---------------------------------------------------------\n",
      "newsgroup20          train/test 11314/7532 total vocab 282099\n",
      "                    ---------------------------------------------------------\n",
      "    Logistic C=1000 | TRAIN 107.1s | EVAL   0.4s | TRAIN/TEST acc 0.97/0.64 |\n",
      "           Logistic | TRAIN  55.5s | EVAL   0.4s | TRAIN/TEST acc 0.69/0.55 |\n",
      "    RandomForest 10 | TRAIN   2.5s | EVAL   0.8s | TRAIN/TEST acc 0.97/0.46 |\n",
      "                    ---------------------------------------------------------\n",
      "reuters              train/test 7769/3019 total vocab 70000\n",
      "                    ---------------------------------------------------------\n",
      "    Logistic C=1000 | TRAIN 227.4s | EVAL   1.5s | TRAIN/TEST acc 0.99/0.78 |\n",
      "    RandomForest 10 | TRAIN  28.2s | EVAL  31.0s | TRAIN/TEST acc 0.95/0.65 |\n",
      "           Logistic | TRAIN 106.1s | EVAL   1.5s | TRAIN/TEST acc 0.64/0.63 |\n",
      "                    ---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for dataset in list_of_datasets:\n",
    "    dataset[\"X_train_vec\"], dataset[\"X_test_vec\"] = vectorize(HashingVectorizer(n_features = 50000, analyzer=\"char_wb\", ngram_range=[2,5]), \n",
    "                                                              dataset[\"X_train\"], dataset[\"X_test\"])\n",
    "\n",
    "models_eval(list_of_models, list_of_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor(x):\n",
    "    return re.sub(r\"[ ]+\", \" \", re.sub(r\"[^\\w]+\", \" \", x)).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_prepare(dataset, by_words=True):\n",
    "    if by_words:\n",
    "        return [preprocessor(line).split() for line in dataset]\n",
    "    else:\n",
    "        return [list(line) for line in dataset]\n",
    "\n",
    "def w2v_fit(text, size=100, alpha=0.025, window=5, min_count=5, workers=4, iter=5):\n",
    "    w2v_model = Word2Vec(text, size=size, alpha=alpha, window=window, min_count=min_count, workers=workers)\n",
    "    word_vectors = w2v_model.wv\n",
    "    del w2v_model\n",
    "    print(f\"word2vec model has {len(word_vectors.vocab)} words\")\n",
    "    return word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2vec model has 101675 words\n",
      "word2vec model has 52 words\n",
      "word2vec model has 26319 words\n"
     ]
    }
   ],
   "source": [
    "ng_wv = w2v_fit(w2v_prepare(ng_data[\"X_train\"]), min_count=1, iter=50, alpha=0.05)\n",
    "baby_wv = w2v_fit(w2v_prepare(baby_data[\"X_train\"], by_words=False), size=20)\n",
    "reuters_wv = w2v_fit(w2v_prepare(reuters_data[\"X_train\"]), min_count=1, iter=50, alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_transform(text, word_vectors):\n",
    "    vocab = set(word_vectors.vocab)\n",
    "    size = word_vectors.vector_size\n",
    "    vectorized = []\n",
    "    for line in text:\n",
    "        line = list(filter(lambda x: x in vocab, line))\n",
    "        if line:\n",
    "            line = np.mean(list(map(lambda x: word_vectors[x], line)), axis=0)\n",
    "            vectorized.append(line)\n",
    "        else:\n",
    "            vectorized.append(np.zeros(size))\n",
    "    return np.array(vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng_data[\"X_train_wv\"] = w2v_transform(w2v_prepare(ng_data[\"X_train\"]), ng_wv)\n",
    "ng_data[\"X_test_wv\"] = w2v_transform(w2v_prepare(ng_data[\"X_test\"]), ng_wv)\n",
    "\n",
    "baby_data[\"X_train_wv\"] = w2v_transform(w2v_prepare(baby_data[\"X_train\"], by_words=False), baby_wv)\n",
    "baby_data[\"X_test_wv\"] = w2v_transform(w2v_prepare(baby_data[\"X_test\"], by_words=False), baby_wv)\n",
    "\n",
    "reuters_data[\"X_train_wv\"] = w2v_transform(w2v_prepare(reuters_data[\"X_train\"]), reuters_wv)\n",
    "reuters_data[\"X_test_wv\"] = w2v_transform(w2v_prepare(reuters_data[\"X_test\"]), reuters_wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_models = {\"Logistic\" : LogisticRegression(solver=\"lbfgs\", n_jobs = -1), \n",
    "                  \"Logistic C=1000\" : LogisticRegression(solver=\"lbfgs\", n_jobs = -1, C=1000), \n",
    "                  \"RandomForest 10\" : RandomForestClassifier(n_jobs = -1), \n",
    "                  \"RandomForest 100\" : RandomForestClassifier(n_jobs = -1, n_estimators=100), \n",
    "                  \"RandomForest 100/10\" : RandomForestClassifier(n_jobs = -1, n_estimators=100, max_depth=10) \n",
    "                 }\n",
    "\n",
    "list_of_datasets = [ng_data, baby_data, reuters_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newsgroup20          train/test 11314/7532 total vocab 282099\n",
      "                    ---------------------------------------------------------\n",
      "           Logistic | TRAIN   8.5s | EVAL   0.0s | TRAIN/TEST acc 0.53/0.47 |\n",
      "    Logistic C=1000 | TRAIN   8.7s | EVAL   0.0s | TRAIN/TEST acc 0.54/0.47 |\n",
      "RandomForest 100/10 | TRAIN   1.6s | EVAL   0.4s | TRAIN/TEST acc 0.90/0.40 |\n",
      "   RandomForest 100 | TRAIN   2.2s | EVAL   0.6s | TRAIN/TEST acc 0.97/0.40 |\n",
      "    RandomForest 10 | TRAIN   0.4s | EVAL   0.2s | TRAIN/TEST acc 0.97/0.31 |\n",
      "                    ---------------------------------------------------------\n",
      "baby                 train/test 87973/20000 total vocab 52\n",
      "                    ---------------------------------------------------------\n",
      "   RandomForest 100 | TRAIN   7.4s | EVAL   1.2s | TRAIN/TEST acc 0.87/0.65 |\n",
      "RandomForest 100/10 | TRAIN   4.8s | EVAL   0.6s | TRAIN/TEST acc 0.75/0.64 |\n",
      "    RandomForest 10 | TRAIN   1.0s | EVAL   0.3s | TRAIN/TEST acc 0.86/0.63 |\n",
      "    Logistic C=1000 | TRAIN   0.8s | EVAL   0.0s | TRAIN/TEST acc 0.69/0.63 |\n",
      "           Logistic | TRAIN   0.7s | EVAL   0.0s | TRAIN/TEST acc 0.68/0.63 |\n",
      "                    ---------------------------------------------------------\n",
      "reuters              train/test 7769/3019 total vocab 70000\n",
      "                    ---------------------------------------------------------\n",
      "           Logistic | TRAIN  43.8s | EVAL   0.2s | TRAIN/TEST acc 0.72/0.69 |\n",
      "    Logistic C=1000 | TRAIN  52.4s | EVAL   0.1s | TRAIN/TEST acc 0.81/0.67 |\n",
      "RandomForest 100/10 | TRAIN  40.7s | EVAL  18.8s | TRAIN/TEST acc 0.96/0.67 |\n",
      "   RandomForest 100 | TRAIN  41.2s | EVAL  19.1s | TRAIN/TEST acc 1.00/0.67 |\n",
      "    RandomForest 10 | TRAIN  16.0s | EVAL  18.6s | TRAIN/TEST acc 0.93/0.65 |\n",
      "                    ---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "models_eval(list_of_models, list_of_datasets, train_key=\"X_train_wv\", test_key=\"X_test_wv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get a 3.6GB word vector file from [this blogger](http://mccormickml.com/2016/04/12/googles-pretrained-word2vec-model-in-python/) or this [archived Google Code post](https://code.google.com/archive/p/word2vec/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2vec model has 3000000 words\n"
     ]
    }
   ],
   "source": [
    "googlenews = KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary=True)\n",
    "print(f\"word2vec model has {len(googlenews.vocab)} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng_data[\"X_train_wv\"] = w2v_transform(w2v_prepare(ng_data[\"X_train\"]), googlenews)\n",
    "ng_data[\"X_test_wv\"] = w2v_transform(w2v_prepare(ng_data[\"X_test\"]), googlenews)\n",
    "\n",
    "reuters_data[\"X_train_wv\"] = w2v_transform(w2v_prepare(reuters_data[\"X_train\"]), googlenews)\n",
    "reuters_data[\"X_test_wv\"] = w2v_transform(w2v_prepare(reuters_data[\"X_test\"]), googlenews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_models = {\"Logistic\" : LogisticRegression(solver=\"lbfgs\", n_jobs = -1), \n",
    "                  \"Logistic C=1000\" : LogisticRegression(solver=\"lbfgs\", n_jobs = -1, C=1000), \n",
    "                  \"RandomForest 10\" : RandomForestClassifier(n_jobs = -1), \n",
    "                  \"RandomForest 100\" : RandomForestClassifier(n_jobs = -1, n_estimators=100), \n",
    "                  \"RandomForest 100/10\" : RandomForestClassifier(n_jobs = -1, n_estimators=100, max_depth=10) \n",
    "                 }\n",
    "\n",
    "list_of_datasets = [ng_data, reuters_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newsgroup20          train/test 11314/7532 total vocab 282099\n",
      "                    ---------------------------------------------------------\n",
      "           Logistic | TRAIN  11.0s | EVAL   0.0s | TRAIN/TEST acc 0.65/0.60 |\n",
      "    Logistic C=1000 | TRAIN  20.5s | EVAL   0.0s | TRAIN/TEST acc 0.75/0.60 |\n",
      "RandomForest 100/10 | TRAIN   2.6s | EVAL   0.5s | TRAIN/TEST acc 0.95/0.50 |\n",
      "   RandomForest 100 | TRAIN   3.3s | EVAL   0.7s | TRAIN/TEST acc 0.97/0.50 |\n",
      "    RandomForest 10 | TRAIN   0.5s | EVAL   0.2s | TRAIN/TEST acc 0.97/0.34 |\n",
      "                    ---------------------------------------------------------\n",
      "reuters              train/test 7769/3019 total vocab 70000\n",
      "                    ---------------------------------------------------------\n",
      "    Logistic C=1000 | TRAIN  97.4s | EVAL   0.3s | TRAIN/TEST acc 0.94/0.74 |\n",
      "   RandomForest 100 | TRAIN  68.7s | EVAL  19.9s | TRAIN/TEST acc 0.99/0.64 |\n",
      "           Logistic | TRAIN  69.6s | EVAL   0.3s | TRAIN/TEST acc 0.61/0.64 |\n",
      "RandomForest 100/10 | TRAIN  67.2s | EVAL  20.4s | TRAIN/TEST acc 0.96/0.64 |\n",
      "    RandomForest 10 | TRAIN  19.9s | EVAL  18.9s | TRAIN/TEST acc 0.93/0.61 |\n",
      "                    ---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "models_eval(list_of_models, [ng_data, reuters_data], train_key=\"X_train_wv\", test_key=\"X_test_wv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences = [preprocessor(line).split() for line in ng_train_raw.data]\n",
    "test_sentences = [preprocessor(line).split() for line in ng_train_raw.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def keras_data(train_set, test_set, by_words=True, max_unigrams=50000):\n",
    "    train_set = w2v_prepare(train_set, by_words)\n",
    "    test_set = w2v_prepare(test_set, by_words)\n",
    "    \n",
    "    id2word = [i for line in train_set for i in line]\n",
    "    \n",
    "    if max_unigrams > 0:\n",
    "        id2word = Counter(id2word)\n",
    "        id2word = list(id2word.items())\n",
    "        id2word.sort(key=lambda x: -x[1])\n",
    "        id2word = [x[0] for x in id2word[:max_unigrams-1]]\n",
    "        id2word = [\"<NULL>\"] + list(set(id2word))\n",
    "    else:\n",
    "        id2word = [\"<NULL>\"] + list(set(id2word))\n",
    "\n",
    "    word2id = dict()\n",
    "    vocab_size = len(id2word)\n",
    "    print(f\"Size of vocabulary: {vocab_size}\")\n",
    "    for i in range(vocab_size):\n",
    "        word2id[id2word[i]] = i\n",
    "\n",
    "    train_set = [[word2id.get(token, 0) for token in line] for line in train_set]\n",
    "    test_set = [[word2id.get(token, 0) for token in line] for line in test_set]\n",
    "    \n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary: 50000\n",
      "Size of vocabulary: 53\n",
      "Size of vocabulary: 26320\n"
     ]
    }
   ],
   "source": [
    "ng_data[\"X_train_ids\"], ng_data[\"X_test_ids\"] = keras_data(ng_data[\"X_train\"], ng_data[\"X_test\"])\n",
    "baby_data[\"X_train_ids\"], baby_data[\"X_test_ids\"] = keras_data(baby_data[\"X_train\"], baby_data[\"X_test\"], by_words=False)\n",
    "reuters_data[\"X_train_ids\"], reuters_data[\"X_test_ids\"] = keras_data(reuters_data[\"X_train\"], reuters_data[\"X_test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/keras-team/keras/blob/master/examples/imdb_fasttext.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 3s 102us/step - loss: 0.4574 - acc: 0.8048 - val_loss: 0.3218 - val_acc: 0.8791\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 2s 65us/step - loss: 0.2366 - acc: 0.9143 - val_loss: 0.2900 - val_acc: 0.8805\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 1s 59us/step - loss: 0.1635 - acc: 0.9440 - val_loss: 0.2852 - val_acc: 0.8860\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 1s 59us/step - loss: 0.1174 - acc: 0.9628 - val_loss: 0.2976 - val_acc: 0.8857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f27fdf7add8>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = sequence.pad_sequences(imdb_data[\"X_train_ids\"], maxlen=400)\n",
    "x_test = sequence.pad_sequences(imdb_data[\"X_test_ids\"], maxlen=400)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(50000, 4, input_length=400))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = Adam(lr=0.01)\n",
    "    \n",
    "model.compile(loss='binary_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(min_delta=0.01, patience=2)\n",
    "\n",
    "model.fit(x_train, imdb_data[\"y_train\"],\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          callbacks=[early_stop],\n",
    "          validation_data=(x_test, imdb_data[\"y_test\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11314 samples, validate on 7532 samples\n",
      "Epoch 1/10\n",
      "11314/11314 [==============================] - 1s 62us/step - loss: 2.7775 - acc: 0.1846 - val_loss: 2.4635 - val_acc: 0.3355\n",
      "Epoch 2/10\n",
      "11314/11314 [==============================] - 0s 43us/step - loss: 1.9913 - acc: 0.5210 - val_loss: 1.8615 - val_acc: 0.5311\n",
      "Epoch 3/10\n",
      "11314/11314 [==============================] - 0s 43us/step - loss: 1.4031 - acc: 0.7001 - val_loss: 1.5526 - val_acc: 0.6127\n",
      "Epoch 4/10\n",
      "11314/11314 [==============================] - 0s 44us/step - loss: 1.0516 - acc: 0.7833 - val_loss: 1.4160 - val_acc: 0.6194\n",
      "Epoch 5/10\n",
      "11314/11314 [==============================] - 0s 44us/step - loss: 0.8204 - acc: 0.8406 - val_loss: 1.3184 - val_acc: 0.6511\n",
      "Epoch 6/10\n",
      "11314/11314 [==============================] - 1s 45us/step - loss: 0.6678 - acc: 0.8657 - val_loss: 1.2868 - val_acc: 0.6573\n",
      "Epoch 7/10\n",
      "11314/11314 [==============================] - 0s 43us/step - loss: 0.5553 - acc: 0.8912 - val_loss: 1.2594 - val_acc: 0.6620\n",
      "Epoch 8/10\n",
      "11314/11314 [==============================] - 0s 43us/step - loss: 0.4689 - acc: 0.9121 - val_loss: 1.2386 - val_acc: 0.6717\n",
      "Epoch 9/10\n",
      "11314/11314 [==============================] - 0s 44us/step - loss: 0.4056 - acc: 0.9268 - val_loss: 1.2358 - val_acc: 0.6733\n",
      "Epoch 10/10\n",
      "11314/11314 [==============================] - 0s 44us/step - loss: 0.3538 - acc: 0.9345 - val_loss: 1.2540 - val_acc: 0.6742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f27fe1759e8>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = sequence.pad_sequences(ng_data[\"X_train_ids\"], maxlen=400)\n",
    "x_test = sequence.pad_sequences(ng_data[\"X_test_ids\"], maxlen=400)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(50000, 32, input_length=400))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(len(ng_train_raw.target_names), activation='softmax'))\n",
    "\n",
    "optimizer = Adam(lr=0.01)\n",
    "    \n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(min_delta=0.01, patience=2)\n",
    "\n",
    "model.fit(x_train, ng_data[\"y_train\"],\n",
    "          batch_size=64,\n",
    "          epochs=10,\n",
    "          callbacks=[early_stop],\n",
    "          validation_data=(x_test, ng_data[\"y_test\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7769, 90)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reuters_data[\"y_train\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7769 samples, validate on 3019 samples\n",
      "Epoch 1/10\n",
      "7769/7769 [==============================] - 1s 92us/step - loss: 3.2051 - acc: 0.4896 - val_loss: 2.3872 - val_acc: 0.6578\n",
      "Epoch 2/10\n",
      "7769/7769 [==============================] - 0s 63us/step - loss: 1.8795 - acc: 0.7100 - val_loss: 1.7440 - val_acc: 0.7539\n",
      "Epoch 3/10\n",
      "7769/7769 [==============================] - 0s 63us/step - loss: 1.3323 - acc: 0.7979 - val_loss: 1.4929 - val_acc: 0.7767\n",
      "Epoch 4/10\n",
      "7769/7769 [==============================] - 0s 62us/step - loss: 1.0314 - acc: 0.8406 - val_loss: 1.3534 - val_acc: 0.8009\n",
      "Epoch 5/10\n",
      "7769/7769 [==============================] - 0s 64us/step - loss: 0.8363 - acc: 0.8681 - val_loss: 1.2921 - val_acc: 0.8142\n",
      "Epoch 6/10\n",
      "7769/7769 [==============================] - 0s 63us/step - loss: 0.7081 - acc: 0.8835 - val_loss: 1.2458 - val_acc: 0.8264\n",
      "Epoch 7/10\n",
      "7769/7769 [==============================] - 0s 64us/step - loss: 0.6255 - acc: 0.8892 - val_loss: 1.2336 - val_acc: 0.8281\n",
      "Epoch 8/10\n",
      "7769/7769 [==============================] - 0s 63us/step - loss: 0.5737 - acc: 0.8977 - val_loss: 1.2310 - val_acc: 0.8354\n",
      "Epoch 9/10\n",
      "7769/7769 [==============================] - 0s 62us/step - loss: 0.5452 - acc: 0.9023 - val_loss: 1.2410 - val_acc: 0.8374\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f27fd78f898>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = sequence.pad_sequences(reuters_data[\"X_train_ids\"], maxlen=200)\n",
    "x_test = sequence.pad_sequences(reuters_data[\"X_test_ids\"], maxlen=200)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(50000, 64, input_length=200))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(90, activation='softmax'))\n",
    "\n",
    "optimizer = Adam(lr=0.01)\n",
    "    \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(min_delta=0.01, patience=2)\n",
    "\n",
    "model.fit(x_train, reuters_data[\"y_train\"],\n",
    "          batch_size=64,\n",
    "          epochs=10,\n",
    "          callbacks=[early_stop],\n",
    "          validation_data=(x_test, reuters_data[\"y_test\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 87973 samples, validate on 20000 samples\n",
      "Epoch 1/10\n",
      "87973/87973 [==============================] - 23s 265us/step - loss: 0.4535 - acc: 0.7868 - val_loss: 0.4467 - val_acc: 0.7987\n",
      "Epoch 2/10\n",
      "15680/87973 [====>.........................] - ETA: 17s - loss: 0.4349 - acc: 0.7975"
     ]
    }
   ],
   "source": [
    "x_train = sequence.pad_sequences(baby_data[\"X_train_ids\"], maxlen=20)\n",
    "x_test = sequence.pad_sequences(baby_data[\"X_test_ids\"], maxlen=20)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(55, 64, input_length=20))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = Adam(lr=0.01)\n",
    "    \n",
    "model.compile(loss='binary_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(min_delta=0.01, patience=2)\n",
    "\n",
    "model.fit(x_train, baby_data[\"y_train\"],\n",
    "          batch_size=64,\n",
    "          epochs=10,\n",
    "          callbacks=[early_stop],\n",
    "          validation_data=(x_test, baby_data[\"y_test\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
