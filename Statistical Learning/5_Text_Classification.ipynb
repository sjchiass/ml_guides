{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text classification\n",
    "\n",
    "You have a lot of options when trying to classify text. In this guide I'll demonstrate a decent amount of techniques for classifying text in four datasets.\n",
    "\n",
    "1. whether IMDB reviews are positive or negative\n",
    "2. whether a baby name is male or female\n",
    "3. what category a newsgroup post belongs to\n",
    "4. assign one or more labels to Reuters newswire\n",
    "\n",
    "We'll try a few techniques on these.\n",
    "\n",
    "* scikit-learn bag-of-words models\n",
    "    * binary counting (is there word there or not?)\n",
    "    * interlude: visualizing model parameters\n",
    "    * td-idf, lemmatization, and hashing: better than binary\n",
    "* word2vec embeddings\n",
    "    * embeddings trained in situ\n",
    "    * using large pre-trained embedding models\n",
    "* neural networks\n",
    "    * fasttext-style models\n",
    "    * short example of recurrent networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# load various models from scikit-learn's library\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# scikit-leanr preprocessing\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# also get some metrics to try\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# get data from scikit-learn\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# vectorizing text with scikit-learn\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfVectorizer\n",
    "\n",
    "# a library for visualizing text classification results\n",
    "import eli5\n",
    "\n",
    "# regular expressions in python\n",
    "import re\n",
    "\n",
    "# the numpy library for dealing with arrays\n",
    "import numpy as np\n",
    "\n",
    "# gensim is a word embedding library\n",
    "from gensim.models.word2vec import Word2Vec, LineSentence\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# keras is an easy-to-use neural network library\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense, LSTM, GlobalAveragePooling1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "# the natural language toolkit provides data and some nlp processing\n",
    "import nltk\n",
    "from nltk.corpus import reuters\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# for timing python code\n",
    "import timeit\n",
    "\n",
    "# quickly running a count on a python list\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data\n",
    "\n",
    "### IMDB reviews sentiment analysis\n",
    "\n",
    "This is a neural network ready dataset from [Keras](https://keras.io/datasets/#imdb-movie-reviews-sentiment-classification). The words in the dataset have already been converted into integer IDs, so you can't easily have a look at what's in there.\n",
    "\n",
    "This is a sentiment analysis or polarity dataset, which means that the target labels are positive or negative. It's a relatively simpler task for a ML model to solve.\n",
    "\n",
    "I'll be using dictionaries to store my data. After I've grabbed the data from keras, I join the integer IDs with spaces to make text for scikit-learn: scikit-learn's vectorizers expect strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_data = {\"name\" : \"imdb\", \"ovr\" : False}\n",
    "(a, b), (c, d) = imdb.load_data(num_words=50000)\n",
    "imdb_data[\"X_train_ids\"], imdb_data[\"y_train\"], imdb_data[\"X_test_ids\"], imdb_data[\"y_test\"] = a, b, c, d\n",
    "\n",
    "# For scikit-learn to like the input data, it will needs strings\n",
    "imdb_data[\"X_train\"] = [\" \".join([str(x) for x in line]) for line in imdb_data[\"X_train_ids\"]]\n",
    "imdb_data[\"X_test\"] = [\" \".join([str(x) for x in line]) for line in imdb_data[\"X_test_ids\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a look at what we're dealing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations in training data: 25000; test data: 25000\n",
      "Min number of words per line in training set: 11\n",
      "Max number of words per line in training set: 2494\n",
      "Average number of words per line in training set: 238.71364\n",
      "Total vocabulary size: 49998\n"
     ]
    }
   ],
   "source": [
    "imdb_data[\"train_size\"], imdb_data[\"test_size\"] = len(imdb_data[\"X_train\"]), len(imdb_data[\"X_test\"])\n",
    "imdb_data[\"avg_length\"] = sum([len(i) for i in imdb_data[\"X_train_ids\"]])/len(imdb_data[\"X_train_ids\"])\n",
    "imdb_data[\"vocab_size\"] = len(set([i for j in imdb_data[\"X_train_ids\"] for i in j]))\n",
    "\n",
    "print(f\"Observations in training data: {imdb_data['train_size']}; test data: {imdb_data['test_size']}\")\n",
    "print(f\"Min number of words per line in training set: {min([len(i) for i in imdb_data['X_train_ids']])}\")\n",
    "print(f\"Max number of words per line in training set: {max([len(i) for i in imdb_data['X_train_ids']])}\")\n",
    "print(f\"Average number of words per line in training set: {imdb_data['avg_length']}\")\n",
    "print(f\"Total vocabulary size: {imdb_data['vocab_size']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A lot of baby names\n",
    "\n",
    "The US government has made available [baby names](https://catalog.data.gov/dataset/baby-names-from-social-security-card-applications-national-level-data) from social security card applications. These records go back to 1880 and also indicate the sex of the baby. I'll be trying to predict which names are male and which are female.\n",
    "\n",
    "Once you've extracted the files to a folder, the following Python code will join them all into a csv file.\n",
    "\n",
    "```\n",
    "import os\n",
    "import re\n",
    "\n",
    "with open(\"babies.csv\", \"w\") as w:\n",
    "    for f in [f for f in os.listdir(os.getcwd()) if \"txt\" in str(f)]:\n",
    "        with open(f) as f:\n",
    "            year = re.search(r'[\\d]{4}', f.name)[0]\n",
    "            for line in f:\n",
    "                w.write(year+\",\"+line)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What I want to do is sort the names by year, remove all duplicates, and then split older and newer names into the training and test sets, respectively. This way, the test set will tell me if I'm correctly inferring newer names from older names.\n",
    "\n",
    "Below you can see a sample of a few names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1880,Mary,F,7065\\n', '1880,Anna,F,2604\\n', '1880,Emma,F,2003\\n', '1880,Elizabeth,F,1939\\n', '1880,Minnie,F,1746\\n']\n"
     ]
    }
   ],
   "source": [
    "with open(\"babies.csv\") as f:\n",
    "    baby_list = f.readlines()\n",
    "\n",
    "# Sort by first 4 characters, the year\n",
    "baby_list.sort(key=lambda x: x[:4])\n",
    "\n",
    "print(baby_list[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What I'm going to do is keep every combination of name and sex in a `set()`. Python sets do not keep duplicates and are very fast at performing `if x in y` operations, making them perfect for this work. With the names properly organized, it's easy to keep 20,000 for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "baby_set = set()\n",
    "unique_baby_list = []\n",
    "\n",
    "for baby in baby_list:\n",
    "    if \" \".join(baby.split(\",\")[1:3]) in baby_set:\n",
    "        pass\n",
    "    else:\n",
    "        baby_set.add(\" \".join(baby.split(\",\")[1:3]))\n",
    "        unique_baby_list.append(baby)\n",
    "\n",
    "# Pick test set\n",
    "baby_train = unique_baby_list[:-20000]\n",
    "baby_test = unique_baby_list[-20000:]\n",
    "\n",
    "baby_data = {\"name\" : \"baby\", \"ovr\" : False}\n",
    "baby_data[\"X_train\"] = [baby.split(\",\")[1] for baby in baby_train]\n",
    "baby_data[\"X_test\"] = [baby.split(\",\")[1] for baby in baby_test]\n",
    "baby_data[\"y_train\"] = [baby.split(\",\")[2] == \"M\" for baby in baby_train]\n",
    "baby_data[\"y_test\"] = [baby.split(\",\")[2] == \"M\" for baby in baby_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data is split by character, we have a small vocabulary size. Even with the removal of duplicates, we still have 100,000+ records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations in training data: 87973; test data: 20000\n",
      "Min number of words per line in training set: 2\n",
      "Max number of words per line in training set: 15\n",
      "Average number of characters per name in training set: 6.442374364861946\n",
      "Total character vocabulary size: 52\n"
     ]
    }
   ],
   "source": [
    "baby_data[\"train_size\"], baby_data[\"test_size\"] = len(baby_data[\"X_train\"]), len(baby_data[\"X_test\"])\n",
    "baby_data[\"avg_length\"] = sum([len(i) for i in baby_data[\"X_train\"]])/len(baby_data[\"X_train\"])\n",
    "baby_data[\"vocab_size\"] = len(set([i for j in baby_data[\"X_train\"] for i in j]))\n",
    "\n",
    "print(f\"Observations in training data: {baby_data['train_size']}; test data: {len(baby_data['X_test'])}\")\n",
    "print(f\"Min number of words per line in training set: {min([len(i) for i in baby_data['X_train']])}\")\n",
    "print(f\"Max number of words per line in training set: {max([len(i) for i in baby_data['X_train']])}\")\n",
    "print(f\"Average number of characters per name in training set: {baby_data['avg_length']}\")\n",
    "print(f\"Total character vocabulary size: {baby_data['vocab_size']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Newsgroup posts\n",
    "\n",
    "These are categorized newsgroup posts you can get [from scikit-learn](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html) ([user guide](scikit-learn.org/stable/datasets/twenty_newsgroups.html). These are rather long and varied texts drawn from 18,000 posts. Each of these belong in a different topic. You can read a bit more about the dataset [here](http://qwone.com/~jason/20Newsgroups/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng_train_raw = fetch_20newsgroups(subset=\"train\", remove=(\"headers\", \"footers\", \"quotes\"))\n",
    "ng_test_raw = fetch_20newsgroups(subset=\"test\", remove=(\"headers\", \"footers\", \"quotes\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a scikit-learn datasource, there are extras you can play with. For example, the target labels can be accessed this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "print(ng_train_raw.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example post looks like this. As you can see, these are multiple sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n"
     ]
    }
   ],
   "source": [
    "print(ng_train_raw.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng_data = {\"name\" : \"newsgroup20\", \"ovr\" : False}\n",
    "ng_data.update({\"X_train\" : ng_train_raw.data, \"y_train\" : ng_train_raw.target})\n",
    "ng_data.update({\"X_test\" : ng_test_raw.data, \"y_test\" : ng_test_raw.target})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On average these posts are shorter than the imdb reviews; however, there are some monster posts lurking in there.\n",
    "\n",
    "The total vocabulary size of the newsgroup set is **much higher** than the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations in training data: 11314; test data: 7532\n",
      "Min number of words per line in training set: 1\n",
      "Max number of words per line in training set: 20083\n",
      "Average number of words per line in training set: 206.15980201520242\n",
      "Total vocabulary size: 282099\n"
     ]
    }
   ],
   "source": [
    "ng_data[\"train_size\"], ng_data[\"test_size\"] = len(ng_data[\"X_train\"]), len(ng_data[\"X_test\"])\n",
    "ng_data[\"avg_length\"] = sum([len(i.split(' ')) for i in ng_data[\"X_train\"]])/len(ng_data[\"X_train\"])\n",
    "ng_data[\"vocab_size\"] = len(set([i.lower() for j in ng_data[\"X_train\"] for i in j.split(\" \")]))\n",
    "\n",
    "print(f\"Observations in training data: {len(ng_data['X_train'])}; test data: {len(ng_data['X_test'])}\")\n",
    "print(f\"Min number of words per line in training set: {min([len(i.split(' ')) for i in ng_data['X_train']])}\")\n",
    "print(f\"Max number of words per line in training set: {max([len(i.split(' ')) for i in ng_data['X_train']])}\")\n",
    "print(f\"Average number of words per line in training set: {ng_data['avg_length']}\")\n",
    "print(f\"Total vocabulary size: {ng_data['vocab_size']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reuters newswire dataset\n",
    "\n",
    "The Reuters dataset is a collection of short categorized news stories. I followed [Martin Thoma's blog post to get started](https://martin-thoma.com/nlp-reuters/).\n",
    "\n",
    "We're usign the nltk version of the dataset, but I'm not sure what that is exactly. Our dataset has 14333 records, but the more popular [reuters-21578](https://archive.ics.uci.edu/ml/datasets/reuters-21578+text+categorization+collection) has 21578. Since that dataset was collected from 1987 newswire texts, I assume the one we're using is similar.\n",
    "\n",
    "To get a copy of the Reuters data, you have to use `nltk.download(\"reuters\")`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_reuters():\n",
    "    reuters_data = {\"name\" : \"reuters\", \"ovr\" : True}\n",
    "    \n",
    "    # The test and train sets are listed as IDs in the .fileids() member\n",
    "    train_ids = list(filter(lambda x: x[:5] == \"train\", reuters.fileids()))\n",
    "    test_ids = list(filter(lambda x: x[:4] == \"test\", reuters.fileids()))\n",
    "    reuters_data[\"X_train\"] = list(map(lambda x: reuters.raw(x), train_ids))\n",
    "    reuters_data[\"X_test\"] = list(map(lambda x: reuters.raw(x), test_ids))\n",
    "    \n",
    "    # The MultiLabelBinarizer will get you the 1s and 0s your model wants\n",
    "    mlb = MultiLabelBinarizer(sparse_output=True)\n",
    "    reuters_data[\"y_train\"] = mlb.fit_transform(list(map(lambda x: reuters.categories(x), train_ids)))\n",
    "    reuters_data[\"y_test\"] = mlb.transform(list(map(lambda x: reuters.categories(x), test_ids)))\n",
    "    \n",
    "    return reuters_data\n",
    "    \n",
    "reuters_data = load_reuters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main challenge with the Reuters dataset are its large amount of classes and their multi-label nature. Models have to cope with these news items belonging to more than one category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example observation targets: ['corn', 'grain', 'rice', 'rubber', 'sugar', 'tin', 'trade']\n",
      "Number of classes: 90\n",
      "['acq', 'alum', 'barley', 'bop', 'carcass', 'castor-oil', 'cocoa', 'coconut', 'coconut-oil', 'coffee', 'copper', 'copra-cake', 'corn', 'cotton', 'cotton-oil', 'cpi', 'cpu', 'crude', 'dfl', 'dlr', 'dmk', 'earn', 'fuel', 'gas', 'gnp', 'gold', 'grain', 'groundnut', 'groundnut-oil', 'heat', 'hog', 'housing', 'income', 'instal-debt', 'interest', 'ipi', 'iron-steel', 'jet', 'jobs', 'l-cattle', 'lead', 'lei', 'lin-oil', 'livestock', 'lumber', 'meal-feed', 'money-fx', 'money-supply', 'naphtha', 'nat-gas', 'nickel', 'nkr', 'nzdlr', 'oat', 'oilseed', 'orange', 'palladium', 'palm-oil', 'palmkernel', 'pet-chem', 'platinum', 'potato', 'propane', 'rand', 'rape-oil', 'rapeseed', 'reserves', 'retail', 'rice', 'rubber', 'rye', 'ship', 'silver', 'sorghum', 'soy-meal', 'soy-oil', 'soybean', 'strategic-metal', 'sugar', 'sun-meal', 'sun-oil', 'sunseed', 'tea', 'tin', 'trade', 'veg-oil', 'wheat', 'wpi', 'yen', 'zinc']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Example observation targets: {reuters.categories('test/14832')}\")\n",
    "print(f\"Number of classes: {len(reuters.categories())}\")\n",
    "print(reuters.categories())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the observations only have one label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min number of target labels: 1\n",
      "Min number of target labels: 15\n",
      "Average number of target labels per observation: 1.235446792732666\n"
     ]
    }
   ],
   "source": [
    "print(f\"Min number of target labels: {min([len(reuters.categories(i)) for i in reuters.fileids()])}\")\n",
    "print(f\"Min number of target labels: {max([len(reuters.categories(i)) for i in reuters.fileids()])}\")\n",
    "print(f\"Average number of target labels per observation: {sum([len(reuters.categories(i)) for i in reuters.fileids()])/len(reuters.fileids())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the stats below aren't as high as imdb and newsgroup20, the models will take longer to do the multi-label. I use an `ovr` flag to tell scikit-learn to treat this dataset as a one-vs-rest problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations in training data: 11314; test data: 3019\n",
      "Min number of words per line in training set: 3\n",
      "Max number of words per line in training set: 1571\n",
      "Average number of words per line in training set: 166.21688763032566\n",
      "Total vocabulary size: 70000\n"
     ]
    }
   ],
   "source": [
    "reuters_data[\"train_size\"], reuters_data[\"test_size\"] = len(reuters_data[\"X_train\"]), len(reuters_data[\"X_test\"])\n",
    "reuters_data[\"avg_length\"] = sum([len(i.split(' ')) for i in reuters_data[\"X_train\"]])/len(reuters_data[\"X_train\"])\n",
    "reuters_data[\"vocab_size\"] = len(set([i.lower() for j in reuters_data[\"X_train\"] for i in j.split(\" \")]))\n",
    "\n",
    "print(f\"Observations in training data: {len(ng_data['X_train'])}; test data: {len(reuters_data['X_test'])}\")\n",
    "print(f\"Min number of words per line in training set: {min([len(i.split(' ')) for i in reuters_data['X_train']])}\")\n",
    "print(f\"Max number of words per line in training set: {max([len(i.split(' ')) for i in reuters_data['X_train']])}\")\n",
    "print(f\"Average number of words per line in training set: {sum([len(i.split(' ')) for i in reuters_data['X_train']])/len(reuters_data['X_train'])}\")\n",
    "print(f\"Total vocabulary size: {len(set([i.lower() for j in reuters_data['X_train'] for i in j.split(' ')]))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convenience functions\n",
    "\n",
    "Whenever we want to train on our datasets, we'll have to pre-process them and then train a bunch of different models on them. To do these things I've written some simple functions.\n",
    "\n",
    "The `vectorize()` functions expects one of scikit-learn's [vectorizers](http://scikit-learn.org/stable/modules/feature_extraction.html) as its first argument, and then vectorizes the two datasets it's given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(vectorizer, x_train, x_test=None):\n",
    "    train_vec = vectorizer.fit_transform(x_train)\n",
    "    if x_test:\n",
    "        test_vec = vectorizer.transform(x_test)\n",
    "    else:\n",
    "        test_vec = None\n",
    "    return train_vec, test_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `model_eval()` function iterates over models and datasets, training and evaluating each one. I had originally included more classification metrics, but I found that evaluating test sets so often can take up a lot of time. I'll stick with test accuracy as my main score.\n",
    "\n",
    "When you wrap a model in the [`OneVsRestClassifier()`](http://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html) function, it'll be re-run for each label separately. This makes training take a lot more time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def models_eval(models, datasets, train_key=\"X_train_vec\", test_key=\"X_test_vec\"):\n",
    "    for dataset in datasets:\n",
    "        print(f\"{dataset['name']:20} train/test {dataset['train_size']}/{dataset['test_size']} total vocab {dataset['vocab_size']}\")\n",
    "        print(f\"{20*' '}{57*'-'}\")\n",
    "        results = []\n",
    "        for name, model in models.items():\n",
    "            if dataset[\"ovr\"]: model = OneVsRestClassifier(model)\n",
    "            timer = timeit.default_timer()\n",
    "            model.fit(dataset[train_key], dataset[\"y_train\"])\n",
    "            train_elapsed = timeit.default_timer() - timer\n",
    "            timer = timeit.default_timer()\n",
    "            train_acc = accuracy_score(y_true = dataset[\"y_train\"], y_pred = model.predict(X=dataset[train_key]))\n",
    "            test_acc = accuracy_score(y_true = dataset[\"y_test\"], y_pred = model.predict(X=dataset[test_key]))\n",
    "            eval_elapsed = timeit.default_timer() - timer\n",
    "            results.append({\n",
    "                \"name\" : name, \n",
    "                \"model\" : model, \n",
    "                \"train_acc\" : train_acc, \n",
    "                \"test_acc\" : test_acc, \n",
    "                \"train_elapsed\" : train_elapsed, \n",
    "                \"eval_elapsed\" : eval_elapsed\n",
    "                })\n",
    "        results.sort(key=lambda x: -x[\"test_acc\"])\n",
    "        for result in results:\n",
    "            print(\"{:>19} | TRAIN {:5.1f}s | EVAL {:5.1f}s | TRAIN/TEST acc {:4.2f}/{:4.2f} |\".format(\n",
    "                result[\"name\"], \n",
    "                result[\"train_elapsed\"], \n",
    "                result[\"eval_elapsed\"], \n",
    "                result[\"train_acc\"], \n",
    "                result[\"test_acc\"]\n",
    "            ))\n",
    "        print(20*\" \"+57*\"-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text classification with basic vectorization\n",
    "\n",
    "We will start off out adventure with the easy-to-use [vectorizers](http://scikit-learn.org/stable/modules/feature_extraction.html) in scikit-learn. Without much effort these will give good results, which shows how useful a well-organized library like scikit-learn is.\n",
    "\n",
    "My choice of models comes down to whatever will run reasonably fast. I learned about LogisticRegression's `C=` parameter from [Martin Thoma's blog post](https://martin-thoma.com/nlp-reuters/). It's a parameter that's easy to miss in the [scikit-learn documentation](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html), but it sometimes gives really nice results.\n",
    "\n",
    "As I'm starting with word-based vectorization, I won't use the `baby` dataset just yet. I'll need character-level vectorization for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_models = {\"Logistic\" : LogisticRegression(solver=\"lbfgs\", n_jobs = -1), \n",
    "                  \"Logistic C=1000\" : LogisticRegression(solver=\"lbfgs\", n_jobs = -1, C=1000), \n",
    "                  \"RandomForest 10\" : RandomForestClassifier(n_jobs = -1), \n",
    "                  \"RandomForest 100\" : RandomForestClassifier(n_jobs = -1, n_estimators=100), \n",
    "                  \"RndForest 100 MD25\" : RandomForestClassifier(n_jobs = -1, n_estimators=100, max_depth=25), \n",
    "                  \"DecisionTree\" : DecisionTreeClassifier(), \n",
    "                  \"DecisionTree MD25\" : DecisionTreeClassifier(max_depth=25), \n",
    "                  \"MultinomialNB\":MultinomialNB()\n",
    "                 }\n",
    "\n",
    "list_of_datasets = [imdb_data, ng_data, reuters_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The simplest bag of words\n",
    "\n",
    "We'll start with the most simple. If a word is present, it gets a 1; otherwise it gets a 0.\n",
    "\n",
    "Whenever we test for words and flag them to the models, we're using a technique called \"bag of words\". Even if we're identifiying short sequences of words, like the presence of \"not good\" or \"red meat\", it's still bag of words, or maybe called bag of n-grams. The common alternative is modelling the sequence of words directly, as a kind of time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imdb                 train/test 25000/25000 total vocab 49998\n",
      "                    ---------------------------------------------------------\n",
      "           Logistic | TRAIN   1.8s | EVAL   0.0s | TRAIN/TEST acc 1.00/0.87 |\n",
      "    Logistic C=1000 | TRAIN   1.6s | EVAL   0.0s | TRAIN/TEST acc 1.00/0.86 |\n",
      "   RandomForest 100 | TRAIN  12.1s | EVAL   1.2s | TRAIN/TEST acc 1.00/0.85 |\n",
      " RndForest 100 MD25 | TRAIN   2.2s | EVAL   0.8s | TRAIN/TEST acc 0.95/0.84 |\n",
      "      MultinomialNB | TRAIN   0.0s | EVAL   0.0s | TRAIN/TEST acc 0.90/0.83 |\n",
      "    RandomForest 10 | TRAIN   1.6s | EVAL   0.3s | TRAIN/TEST acc 0.99/0.75 |\n",
      "  DecisionTree MD25 | TRAIN  10.8s | EVAL   0.0s | TRAIN/TEST acc 0.89/0.73 |\n",
      "       DecisionTree | TRAIN  23.6s | EVAL   0.0s | TRAIN/TEST acc 1.00/0.71 |\n",
      "                    ---------------------------------------------------------\n",
      "newsgroup20          train/test 11314/7532 total vocab 282099\n",
      "                    ---------------------------------------------------------\n",
      "           Logistic | TRAIN  14.3s | EVAL   0.0s | TRAIN/TEST acc 0.97/0.62 |\n",
      "      MultinomialNB | TRAIN   0.0s | EVAL   0.0s | TRAIN/TEST acc 0.81/0.62 |\n",
      "   RandomForest 100 | TRAIN   7.2s | EVAL   1.3s | TRAIN/TEST acc 0.97/0.60 |\n",
      "    Logistic C=1000 | TRAIN  18.3s | EVAL   0.0s | TRAIN/TEST acc 0.97/0.59 |\n",
      " RndForest 100 MD25 | TRAIN   0.7s | EVAL   1.0s | TRAIN/TEST acc 0.77/0.57 |\n",
      "    RandomForest 10 | TRAIN   0.9s | EVAL   0.3s | TRAIN/TEST acc 0.97/0.44 |\n",
      "       DecisionTree | TRAIN   6.6s | EVAL   0.0s | TRAIN/TEST acc 0.97/0.41 |\n",
      "  DecisionTree MD25 | TRAIN   1.6s | EVAL   0.0s | TRAIN/TEST acc 0.41/0.29 |\n",
      "                    ---------------------------------------------------------\n",
      "reuters              train/test 7769/3019 total vocab 70000\n",
      "                    ---------------------------------------------------------\n",
      "    Logistic C=1000 | TRAIN  40.7s | EVAL   0.1s | TRAIN/TEST acc 1.00/0.75 |\n",
      "           Logistic | TRAIN  38.1s | EVAL   0.1s | TRAIN/TEST acc 0.99/0.74 |\n",
      "       DecisionTree | TRAIN   6.9s | EVAL   0.2s | TRAIN/TEST acc 0.99/0.70 |\n",
      "  DecisionTree MD25 | TRAIN   6.0s | EVAL   0.2s | TRAIN/TEST acc 0.97/0.69 |\n",
      "      MultinomialNB | TRAIN   0.3s | EVAL   0.3s | TRAIN/TEST acc 0.68/0.66 |\n",
      "   RandomForest 100 | TRAIN  28.4s | EVAL  26.4s | TRAIN/TEST acc 1.00/0.64 |\n",
      "    RandomForest 10 | TRAIN  11.0s | EVAL  18.5s | TRAIN/TEST acc 0.95/0.60 |\n",
      " RndForest 100 MD25 | TRAIN  24.1s | EVAL  25.5s | TRAIN/TEST acc 0.83/0.55 |\n",
      "                    ---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for dataset in list_of_datasets:\n",
    "    dataset[\"X_train_vec\"], dataset[\"X_test_vec\"] = vectorize(CountVectorizer(max_features=50000, binary=True), dataset[\"X_train\"], dataset[\"X_test\"])\n",
    "\n",
    "models_eval(list_of_models, list_of_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interlude: the evils of overfitting\n",
    "\n",
    "If you're like most people, you enjoy nice colorful representations of model output. The [`eli5`](http://eli5.readthedocs.io/en/latest/tutorials/sklearn-text.html) has a few things to help you out there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer(max_features=50000, binary=True).fit(ng_data[\"X_train\"])\n",
    "\n",
    "model = LogisticRegression(solver=\"lbfgs\", n_jobs = -1, C=1000)\n",
    "\n",
    "fit = model.fit(ng_data[\"X_train_vec\"], ng_data[\"y_train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first entry in the newsgroup20 is about cars, and you can see how the logistic model weighs different words. Words like car, bumper, and engine are all positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "\n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=rec.autos\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>1.000</b>, score <b>30.378</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +32.575\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 96.97%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -2.196\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"opacity: 0.80\">i </span><span style=\"background-color: hsl(0, 100.00%, 92.75%); opacity: 0.82\" title=\"-0.376\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 62.20%); opacity: 0.98\" title=\"3.980\">wondering</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.32%); opacity: 0.81\" title=\"0.143\">if</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.33%); opacity: 0.85\" title=\"-1.030\">anyone</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 71.49%); opacity: 0.92\" title=\"2.660\">out</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.62%); opacity: 0.83\" title=\"-0.543\">there</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.15%); opacity: 0.84\" title=\"0.852\">could</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.55%); opacity: 0.80\" title=\"0.038\">enlighten</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 71.07%); opacity: 0.93\" title=\"-2.717\">me</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.21%); opacity: 0.82\" title=\"-0.495\">on</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.68%); opacity: 0.81\" title=\"-0.180\">this</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 67.54%); opacity: 0.95\" title=\"3.202\">car</span><span style=\"opacity: 0.80\"> i </span><span style=\"background-color: hsl(120, 100.00%, 87.40%); opacity: 0.84\" title=\"0.829\">saw</span><span style=\"opacity: 0.80\">\n",
       "</span><span style=\"background-color: hsl(0, 100.00%, 94.89%); opacity: 0.81\" title=\"-0.228\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.07%); opacity: 0.84\" title=\"0.766\">other</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.63%); opacity: 0.81\" title=\"-0.313\">day</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 88.29%); opacity: 0.83\" title=\"-0.746\">it</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.75%); opacity: 0.82\" title=\"-0.376\">was</span><span style=\"opacity: 0.80\"> a 2-</span><span style=\"background-color: hsl(120, 100.00%, 80.09%); opacity: 0.87\" title=\"1.593\">door</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.85%); opacity: 0.84\" title=\"0.880\">sports</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 67.54%); opacity: 0.95\" title=\"3.202\">car</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 91.39%); opacity: 0.82\" title=\"0.481\">looked</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.28%); opacity: 0.85\" title=\"-1.035\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.94%); opacity: 0.85\" title=\"-1.172\">be</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.32%); opacity: 0.83\" title=\"-0.569\">from</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.89%); opacity: 0.81\" title=\"-0.228\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.01%); opacity: 0.82\" title=\"0.432\">late</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.00%); opacity: 0.83\" title=\"0.595\">60s</span><span style=\"opacity: 0.80\">/\n",
       "</span><span style=\"background-color: hsl(120, 100.00%, 69.59%); opacity: 0.94\" title=\"2.917\">early</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.91%); opacity: 0.86\" title=\"1.281\">70s</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 88.29%); opacity: 0.83\" title=\"-0.746\">it</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.75%); opacity: 0.82\" title=\"-0.376\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.19%); opacity: 0.83\" title=\"0.666\">called</span><span style=\"opacity: 0.80\"> a </span><span style=\"background-color: hsl(120, 100.00%, 97.40%); opacity: 0.80\" title=\"0.087\">bricklin</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 94.89%); opacity: 0.81\" title=\"-0.228\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"4.315\">doors</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 76.57%); opacity: 0.89\" title=\"2.009\">were</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 75.81%); opacity: 0.90\" title=\"2.103\">really</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.41%); opacity: 0.87\" title=\"1.444\">small</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 87.47%); opacity: 0.84\" title=\"-0.822\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.94%); opacity: 0.86\" title=\"1.278\">addition</span><span style=\"opacity: 0.80\">,\n",
       "</span><span style=\"background-color: hsl(0, 100.00%, 94.89%); opacity: 0.81\" title=\"-0.228\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.03%); opacity: 0.80\" title=\"0.058\">front</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 72.98%); opacity: 0.91\" title=\"2.464\">bumper</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.75%); opacity: 0.82\" title=\"-0.376\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.43%); opacity: 0.82\" title=\"0.400\">separate</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.32%); opacity: 0.83\" title=\"-0.569\">from</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.89%); opacity: 0.81\" title=\"-0.228\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.45%); opacity: 0.81\" title=\"-0.257\">rest</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.40%); opacity: 0.84\" title=\"-0.828\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.89%); opacity: 0.81\" title=\"-0.228\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 77.97%); opacity: 0.89\" title=\"1.841\">body</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 95.68%); opacity: 0.81\" title=\"-0.180\">this</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.02%); opacity: 0.84\" title=\"-0.865\">is</span><span style=\"opacity: 0.80\"> \n",
       "</span><span style=\"background-color: hsl(120, 100.00%, 91.68%); opacity: 0.82\" title=\"0.458\">all</span><span style=\"opacity: 0.80\"> i </span><span style=\"background-color: hsl(120, 100.00%, 78.04%); opacity: 0.88\" title=\"1.832\">know</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 96.32%); opacity: 0.81\" title=\"0.143\">if</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.33%); opacity: 0.85\" title=\"-1.030\">anyone</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.75%); opacity: 0.84\" title=\"-0.795\">can</span><span style=\"opacity: 0.80\"> tellme a </span><span style=\"background-color: hsl(120, 100.00%, 88.35%); opacity: 0.83\" title=\"0.740\">model</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 72.33%); opacity: 0.92\" title=\"2.548\">name</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 62.88%); opacity: 0.98\" title=\"3.878\">engine</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.85%); opacity: 0.83\" title=\"-0.695\">specs</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 83.81%); opacity: 0.85\" title=\"-1.185\">years</span><span style=\"opacity: 0.80\">\n",
       "</span><span style=\"background-color: hsl(0, 100.00%, 87.40%); opacity: 0.84\" title=\"-0.828\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 70.12%); opacity: 0.93\" title=\"2.844\">production</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 85.96%); opacity: 0.84\" title=\"-0.967\">where</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.68%); opacity: 0.81\" title=\"-0.180\">this</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 67.54%); opacity: 0.95\" title=\"3.202\">car</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.02%); opacity: 0.84\" title=\"-0.865\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.15%); opacity: 0.81\" title=\"-0.152\">made</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 99.34%); opacity: 0.80\" title=\"0.012\">history</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 93.73%); opacity: 0.81\" title=\"-0.306\">or</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 80.52%); opacity: 0.87\" title=\"-1.543\">whatever</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.79%); opacity: 0.84\" title=\"0.887\">info</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 78.17%); opacity: 0.88\" title=\"-1.816\">you</span><span style=\"opacity: 0.80\">\n",
       "</span><span style=\"background-color: hsl(120, 100.00%, 86.75%); opacity: 0.84\" title=\"0.890\">have</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.21%); opacity: 0.82\" title=\"-0.495\">on</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.68%); opacity: 0.81\" title=\"-0.180\">this</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.42%); opacity: 0.80\" title=\"0.086\">funky</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.41%); opacity: 0.85\" title=\"-1.123\">looking</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 67.54%); opacity: 0.95\" title=\"3.202\">car</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 78.06%); opacity: 0.88\" title=\"-1.830\">please</span><span style=\"opacity: 0.80\"> e-</span><span style=\"background-color: hsl(120, 100.00%, 83.04%); opacity: 0.86\" title=\"1.266\">mail</span><span style=\"opacity: 0.80\">.</span>\n",
       "    </p>\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5.show_prediction(fit, ng_train_raw.data[0], vec=vec, target_names=ng_train_raw.target_names, targets=[\"rec.autos\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can view a more compressed version of the information with the `show_weights()` function. For some reason the word `rectum` is the fourth most important for hockey posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights-wrapper\" style=\"border-collapse: collapse; border: none; margin-bottom: 1.5em;\">\n",
       "            <tr>\n",
       "                \n",
       "                    <td style=\"padding: 0.5em; border: 1px solid black; text-align: center;\">\n",
       "                        <b>\n",
       "    \n",
       "        y=rec.autos\n",
       "    \n",
       "</b>\n",
       "\n",
       "top features\n",
       "                    </td>\n",
       "                \n",
       "                    <td style=\"padding: 0.5em; border: 1px solid black; text-align: center;\">\n",
       "                        <b>\n",
       "    \n",
       "        y=rec.sport.baseball\n",
       "    \n",
       "</b>\n",
       "\n",
       "top features\n",
       "                    </td>\n",
       "                \n",
       "                    <td style=\"padding: 0.5em; border: 1px solid black; text-align: center;\">\n",
       "                        <b>\n",
       "    \n",
       "        y=rec.sport.hockey\n",
       "    \n",
       "</b>\n",
       "\n",
       "top features\n",
       "                    </td>\n",
       "                \n",
       "                    <td style=\"padding: 0.5em; border: 1px solid black; text-align: center;\">\n",
       "                        <b>\n",
       "    \n",
       "        y=sci.med\n",
       "    \n",
       "</b>\n",
       "\n",
       "top features\n",
       "                    </td>\n",
       "                \n",
       "                    <td style=\"padding: 0.5em; border: 1px solid black; text-align: center;\">\n",
       "                        <b>\n",
       "    \n",
       "        y=sci.space\n",
       "    \n",
       "</b>\n",
       "\n",
       "top features\n",
       "                    </td>\n",
       "                \n",
       "            </tr>\n",
       "            <tr>\n",
       "                \n",
       "                    \n",
       "                        <td style=\"padding: 0px; border: 1px solid black; vertical-align: top;\">\n",
       "                            \n",
       "                                \n",
       "                                    \n",
       "                                    \n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; width: 100%;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
       "                    Weight<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +12.807\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        car\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 83.72%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +9.548\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        content\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.91%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +8.562\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        testing\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.02%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +7.675\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        ites\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.13%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +7.590\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        corrected\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.54%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +7.274\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        cars\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.57%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +7.247\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        dealer\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.57%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 14381 more positive &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 86.46%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 35610 more negative &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 86.46%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -7.338\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        refrigerator\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 86.20%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -7.540\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        bike\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 84.25%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -9.105\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        flames\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "                                \n",
       "                            \n",
       "                        </td>\n",
       "                    \n",
       "                        <td style=\"padding: 0px; border: 1px solid black; vertical-align: top;\">\n",
       "                            \n",
       "                                \n",
       "                                    \n",
       "                                    \n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; width: 100%;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
       "                    Weight<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.79%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +8.658\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        baseball\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 85.65%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +7.973\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        braves\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.24%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +7.504\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        sig\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.28%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +7.472\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        cubs\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.29%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +7.469\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        stadium\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.34%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +7.425\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        woof\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.43%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +7.355\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        anaheim\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.64%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +7.199\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        bo\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.72%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +7.135\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        phillies\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.08%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +6.863\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        era\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.08%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 12810 more positive &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 80.00%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 37181 more negative &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "                                \n",
       "                            \n",
       "                        </td>\n",
       "                    \n",
       "                        <td style=\"padding: 0px; border: 1px solid black; vertical-align: top;\">\n",
       "                            \n",
       "                                \n",
       "                                    \n",
       "                                    \n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; width: 100%;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
       "                    Weight<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 81.30%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +11.636\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hockey\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.86%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +8.601\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        nhl\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 85.91%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +7.768\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        trying\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.39%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +7.387\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        rectum\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.08%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +6.858\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        playoff\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.41%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +6.610\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        playoffs\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.50%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +6.542\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        david\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.69%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +6.400\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        mask\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.98%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +6.188\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        puck\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.27%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +5.973\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        leafs\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.27%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 16152 more positive &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 80.00%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 33839 more negative &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "                                \n",
       "                            \n",
       "                        </td>\n",
       "                    \n",
       "                        <td style=\"padding: 0px; border: 1px solid black; vertical-align: top;\">\n",
       "                            \n",
       "                                \n",
       "                                    \n",
       "                                    \n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; width: 100%;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
       "                    Weight<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.57%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +6.489\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        msg\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.70%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +6.392\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        medical\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.41%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +5.874\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        doctor\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.65%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +5.702\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        health\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 89.25%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +5.278\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        treatment\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 89.89%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +4.832\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        effects\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.14%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +4.663\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        needles\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.18%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +4.634\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        foods\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.29%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +4.564\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        syndrome\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.29%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 13724 more positive &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 89.96%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 36267 more negative &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 89.96%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -4.788\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        testing\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "                                \n",
       "                            \n",
       "                        </td>\n",
       "                    \n",
       "                        <td style=\"padding: 0px; border: 1px solid black; vertical-align: top;\">\n",
       "                            \n",
       "                                \n",
       "                                    \n",
       "                                    \n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; width: 100%;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
       "                    Weight<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.30%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +9.062\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        space\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.52%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +8.884\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        orbit\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.93%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +8.548\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        update\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.41%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +7.376\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        ironic\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.42%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +7.368\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        launch\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.27%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +6.715\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        spacecraft\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.42%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +6.602\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        nasa\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.12%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +6.088\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        breathing\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.20%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +6.026\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        solar\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.21%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +6.018\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        allen\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.21%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 14273 more positive &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 80.00%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 35718 more negative &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "                                \n",
       "                            \n",
       "                        </td>\n",
       "                    \n",
       "                \n",
       "            </tr>\n",
       "        </table>\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5.show_weights(fit, vec=vec, top=10, target_names=ng_train_raw.target_names, \n",
    "                  targets=[\"rec.autos\", \"rec.sport.baseball\", \"rec.sport.hockey\", \"sci.med\", \"sci.space\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this particular example is a bit crude, it is a case of a model overfitting. The word only appears once in the data as a joke, yet it will influence all future predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rec.sport.hockey\n"
     ]
    }
   ],
   "source": [
    "wikipedia = \"The rectum is the final straight portion of the large intestine.\"\n",
    "\n",
    "print(ng_train_raw.target_names[model.predict(vec.transform([wikipedia]))[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tdidf with unigrams\n",
    "\n",
    "Compared to binary counting, here is a better approach: the [Term Document Inverser Document Frequency (TD-IDF) vectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html). This vectorizer will count word occurences in a sentence (or \"document\") but then divide these counts with how frequent each word appears in general. For example, if *aardvark* appears once in a sentence and once in the entire corpus, it gets a count of 1; however, if *and* appears once in a sentence but 10,000 times in the corpus, it gets a TD-IDF count of 0.0001. td-idf normalizes your data in a way that gives an edge to rarer words but a penalty to more common words.\n",
    "\n",
    "According to [this Wikipedia article](https://en.wikipedia.org/wiki/Tf%E2%80%93idf), 83% of text classification tasks use TD-IDF.\n",
    "\n",
    "Anyways, I'll keep setting the maximum vocabulary size to 50,000 to make of these examples roughly comparable. Increasing the maximum vocabulary usually increases model accuracy. When scikit-learn is given a max vocabulary size, it'll only keep the most frequent words.\n",
    "\n",
    "We should get **89%** for imdb, **68%** for newsgroup20, and **80%** for reuters. These are the amounts we'll try to beat afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imdb                 train/test 25000/25000 total vocab 49998\n",
      "                    ---------------------------------------------------------\n",
      "           Logistic | TRAIN   0.8s | EVAL   0.0s | TRAIN/TEST acc 0.93/0.89 |\n",
      "    Logistic C=1000 | TRAIN   1.4s | EVAL   0.0s | TRAIN/TEST acc 1.00/0.86 |\n",
      "   RandomForest 100 | TRAIN   9.7s | EVAL   1.1s | TRAIN/TEST acc 1.00/0.84 |\n",
      " RndForest 100 MD25 | TRAIN   2.7s | EVAL   0.9s | TRAIN/TEST acc 0.97/0.84 |\n",
      "      MultinomialNB | TRAIN   0.0s | EVAL   0.0s | TRAIN/TEST acc 0.90/0.83 |\n",
      "    RandomForest 10 | TRAIN   1.4s | EVAL   0.4s | TRAIN/TEST acc 0.99/0.74 |\n",
      "  DecisionTree MD25 | TRAIN  12.7s | EVAL   0.0s | TRAIN/TEST acc 0.91/0.72 |\n",
      "       DecisionTree | TRAIN  24.3s | EVAL   0.0s | TRAIN/TEST acc 1.00/0.71 |\n",
      "                    ---------------------------------------------------------\n",
      "newsgroup20          train/test 11314/7532 total vocab 282099\n",
      "                    ---------------------------------------------------------\n",
      "           Logistic | TRAIN   5.1s | EVAL   0.0s | TRAIN/TEST acc 0.88/0.67 |\n",
      "    Logistic C=1000 | TRAIN  12.6s | EVAL   0.0s | TRAIN/TEST acc 0.97/0.66 |\n",
      "      MultinomialNB | TRAIN   0.0s | EVAL   0.0s | TRAIN/TEST acc 0.82/0.64 |\n",
      "   RandomForest 100 | TRAIN   5.0s | EVAL   1.1s | TRAIN/TEST acc 0.97/0.59 |\n",
      " RndForest 100 MD25 | TRAIN   0.8s | EVAL   0.7s | TRAIN/TEST acc 0.79/0.56 |\n",
      "    RandomForest 10 | TRAIN   0.7s | EVAL   0.3s | TRAIN/TEST acc 0.97/0.46 |\n",
      "       DecisionTree | TRAIN   7.4s | EVAL   0.0s | TRAIN/TEST acc 0.97/0.40 |\n",
      "  DecisionTree MD25 | TRAIN   2.6s | EVAL   0.0s | TRAIN/TEST acc 0.41/0.28 |\n",
      "                    ---------------------------------------------------------\n",
      "reuters              train/test 7769/3019 total vocab 70000\n",
      "                    ---------------------------------------------------------\n",
      "    Logistic C=1000 | TRAIN  37.7s | EVAL   0.1s | TRAIN/TEST acc 0.99/0.80 |\n",
      "  DecisionTree MD25 | TRAIN  20.1s | EVAL   0.2s | TRAIN/TEST acc 0.98/0.69 |\n",
      "       DecisionTree | TRAIN  22.8s | EVAL   0.2s | TRAIN/TEST acc 0.99/0.69 |\n",
      "           Logistic | TRAIN  29.8s | EVAL   0.1s | TRAIN/TEST acc 0.73/0.68 |\n",
      "   RandomForest 100 | TRAIN  30.7s | EVAL  21.9s | TRAIN/TEST acc 0.99/0.67 |\n",
      "    RandomForest 10 | TRAIN  10.8s | EVAL  18.5s | TRAIN/TEST acc 0.95/0.62 |\n",
      " RndForest 100 MD25 | TRAIN  27.3s | EVAL  20.5s | TRAIN/TEST acc 0.93/0.62 |\n",
      "      MultinomialNB | TRAIN   0.2s | EVAL   0.3s | TRAIN/TEST acc 0.57/0.58 |\n",
      "                    ---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for dataset in list_of_datasets:\n",
    "    dataset[\"X_train_vec\"], dataset[\"X_test_vec\"] = vectorize(TfidfVectorizer(max_features=50000, min_df=5), dataset[\"X_train\"], dataset[\"X_test\"])\n",
    "\n",
    "models_eval(list_of_models, list_of_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tdidf with bigrams\n",
    "\n",
    "We can help the models by informing them of some short word sequences, say sequences of two: these are called bi-grams. For example the imdb models will get a bit of extra help by knowing the presence of \"not good\" instead of only \"not\" and \"good\" separately; this helps in the sentiment analysis task.\n",
    "\n",
    "We get a slight increase with with **90%** for imdb but decreases with **67%** for newsgroup20 and **79%** for reuters. Some rarer words are important to the models, and they're being pushed out by more common bi-grams. Increasing the `max_features` to 75,000 doesn't make a lot of difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imdb                 train/test 25000/25000 total vocab 49998\n",
      "                    ---------------------------------------------------------\n",
      "           Logistic | TRAIN   2.2s | EVAL   0.0s | TRAIN/TEST acc 0.95/0.90 |\n",
      "    Logistic C=1000 | TRAIN   2.5s | EVAL   0.0s | TRAIN/TEST acc 1.00/0.89 |\n",
      "      MultinomialNB | TRAIN   0.0s | EVAL   0.0s | TRAIN/TEST acc 0.92/0.88 |\n",
      "   RandomForest 100 | TRAIN  12.1s | EVAL   1.4s | TRAIN/TEST acc 1.00/0.85 |\n",
      " RndForest 100 MD25 | TRAIN   2.8s | EVAL   1.3s | TRAIN/TEST acc 0.96/0.85 |\n",
      "    RandomForest 10 | TRAIN   1.6s | EVAL   0.6s | TRAIN/TEST acc 0.99/0.76 |\n",
      "  DecisionTree MD25 | TRAIN  20.5s | EVAL   0.0s | TRAIN/TEST acc 0.91/0.72 |\n",
      "       DecisionTree | TRAIN  37.7s | EVAL   0.1s | TRAIN/TEST acc 1.00/0.71 |\n",
      "                    ---------------------------------------------------------\n",
      "newsgroup20          train/test 11314/7532 total vocab 282099\n",
      "                    ---------------------------------------------------------\n",
      "    Logistic C=1000 | TRAIN  24.7s | EVAL   0.1s | TRAIN/TEST acc 0.97/0.67 |\n",
      "           Logistic | TRAIN   9.5s | EVAL   0.1s | TRAIN/TEST acc 0.91/0.66 |\n",
      "      MultinomialNB | TRAIN   0.0s | EVAL   0.0s | TRAIN/TEST acc 0.85/0.61 |\n",
      "   RandomForest 100 | TRAIN   8.1s | EVAL   1.6s | TRAIN/TEST acc 0.97/0.59 |\n",
      " RndForest 100 MD25 | TRAIN   0.8s | EVAL   1.1s | TRAIN/TEST acc 0.78/0.56 |\n",
      "    RandomForest 10 | TRAIN   1.0s | EVAL   0.3s | TRAIN/TEST acc 0.97/0.45 |\n",
      "       DecisionTree | TRAIN  13.1s | EVAL   0.0s | TRAIN/TEST acc 0.97/0.40 |\n",
      "  DecisionTree MD25 | TRAIN   4.6s | EVAL   0.0s | TRAIN/TEST acc 0.40/0.28 |\n",
      "                    ---------------------------------------------------------\n",
      "reuters              train/test 7769/3019 total vocab 70000\n",
      "                    ---------------------------------------------------------\n",
      "    Logistic C=1000 | TRAIN  61.7s | EVAL   0.2s | TRAIN/TEST acc 1.00/0.79 |\n",
      "  DecisionTree MD25 | TRAIN  37.5s | EVAL   0.5s | TRAIN/TEST acc 0.98/0.71 |\n",
      "       DecisionTree | TRAIN  41.1s | EVAL   0.5s | TRAIN/TEST acc 0.99/0.70 |\n",
      "   RandomForest 100 | TRAIN  37.2s | EVAL  41.4s | TRAIN/TEST acc 0.99/0.68 |\n",
      "           Logistic | TRAIN  42.3s | EVAL   0.2s | TRAIN/TEST acc 0.68/0.64 |\n",
      "    RandomForest 10 | TRAIN  12.5s | EVAL  18.7s | TRAIN/TEST acc 0.95/0.64 |\n",
      " RndForest 100 MD25 | TRAIN  30.5s | EVAL  44.7s | TRAIN/TEST acc 0.85/0.59 |\n",
      "      MultinomialNB | TRAIN   0.5s | EVAL   0.5s | TRAIN/TEST acc 0.54/0.53 |\n",
      "                    ---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for dataset in list_of_datasets:\n",
    "    dataset[\"X_train_vec\"], dataset[\"X_test_vec\"] = vectorize(TfidfVectorizer(max_features=50000, ngram_range = [1, 2]), dataset[\"X_train\"], dataset[\"X_test\"])\n",
    "\n",
    "models_eval(list_of_models, list_of_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing\n",
    "\n",
    "Before we move on to other things, we can try pre-processing our text data further. I got the lemmatization code [here](http://scikit-learn.org/stable/modules/feature_extraction.html#customizing-the-vectorizer-classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can see that this beats the best we had so far. It won't work with the imdb set. With 75,000 and 1,2 ngrams we get **67%** for newsgroup20 and **80%** for reuters. With only 1,1, we **81%** for reuters, which is out best so far. Newsgroup20 gets **66%**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_datasets = [ng_data, reuters_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newsgroup20          train/test 11314/7532 total vocab 282099\n",
      "                    ---------------------------------------------------------\n",
      "    Logistic C=1000 | TRAIN  16.3s | EVAL   0.0s | TRAIN/TEST acc 0.97/0.66 |\n",
      "           Logistic | TRAIN   7.3s | EVAL   0.0s | TRAIN/TEST acc 0.87/0.66 |\n",
      "      MultinomialNB | TRAIN   0.0s | EVAL   0.0s | TRAIN/TEST acc 0.83/0.64 |\n",
      "   RandomForest 100 | TRAIN   6.5s | EVAL   1.1s | TRAIN/TEST acc 0.97/0.61 |\n",
      " RndForest 100 MD25 | TRAIN   0.7s | EVAL   0.7s | TRAIN/TEST acc 0.77/0.58 |\n",
      "    RandomForest 10 | TRAIN   0.9s | EVAL   0.3s | TRAIN/TEST acc 0.97/0.49 |\n",
      "       DecisionTree | TRAIN   6.6s | EVAL   0.0s | TRAIN/TEST acc 0.97/0.41 |\n",
      "  DecisionTree MD25 | TRAIN   2.3s | EVAL   0.0s | TRAIN/TEST acc 0.45/0.31 |\n",
      "                    ---------------------------------------------------------\n",
      "reuters              train/test 7769/3019 total vocab 70000\n",
      "                    ---------------------------------------------------------\n",
      "    Logistic C=1000 | TRAIN  52.5s | EVAL   0.1s | TRAIN/TEST acc 1.00/0.81 |\n",
      "  DecisionTree MD25 | TRAIN  17.7s | EVAL   0.2s | TRAIN/TEST acc 0.98/0.71 |\n",
      "       DecisionTree | TRAIN  20.3s | EVAL   0.2s | TRAIN/TEST acc 1.00/0.70 |\n",
      "           Logistic | TRAIN  43.1s | EVAL   0.1s | TRAIN/TEST acc 0.72/0.68 |\n",
      "   RandomForest 100 | TRAIN  25.6s | EVAL  26.0s | TRAIN/TEST acc 1.00/0.64 |\n",
      "    RandomForest 10 | TRAIN  12.4s | EVAL  18.9s | TRAIN/TEST acc 0.94/0.61 |\n",
      " RndForest 100 MD25 | TRAIN  20.8s | EVAL  22.2s | TRAIN/TEST acc 0.78/0.54 |\n",
      "      MultinomialNB | TRAIN   0.3s | EVAL   0.3s | TRAIN/TEST acc 0.43/0.38 |\n",
      "                    ---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for dataset in list_of_datasets:\n",
    "    dataset[\"X_train_vec\"], dataset[\"X_test_vec\"] = vectorize(TfidfVectorizer(max_features=50000, ngram_range = [1, 1], \n",
    "                                                                              tokenizer=LemmaTokenizer(), stop_words=\"english\"), \n",
    "                                                              dataset[\"X_train\"], dataset[\"X_test\"])\n",
    "\n",
    "models_eval(list_of_models, list_of_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hashing trick with character ngrams\n",
    "\n",
    "So far we've been setting a limit of 50,000 to our vocabulary. What if we wanted to fit more words into that 50,000, perhaps by some form of compression?\n",
    "\n",
    "The hashing trick hashes words into ID numbers. The same word will be hashed the same way each time, but two words may \"collide\" and get the same ID number. These collisons are bad for classification, but hashing can turn out to be a net good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_models = {\"Logistic\" : LogisticRegression(solver=\"lbfgs\", n_jobs = -1), \n",
    "                  \"Logistic C=1000\" : LogisticRegression(solver=\"lbfgs\", n_jobs = -1, C=1000), \n",
    "                  \"RandomForest 10\" : RandomForestClassifier(n_jobs = -1)\n",
    "                 }\n",
    "\n",
    "list_of_datasets = [imdb_data, baby_data, ng_data, reuters_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason I'm ushing hashing here is to try character n-grams on the baby name dataset. By taking ngrams from 2 to 5, I am going to have a *massive* vocabulary. With hashing it becomes workable.\n",
    "\n",
    "With the baby dataset, its 1-gram vocabulary of 52 becomes 123,084 with `[2,5]` n-grams. For this we get an accuracy score of **81%**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imdb                 train/test 25000/25000 total vocab 49998\n",
      "                    ---------------------------------------------------------\n",
      "    Logistic C=1000 | TRAIN   7.0s | EVAL   0.1s | TRAIN/TEST acc 0.90/0.86 |\n",
      "           Logistic | TRAIN   6.0s | EVAL   0.1s | TRAIN/TEST acc 0.81/0.80 |\n",
      "    RandomForest 10 | TRAIN   2.6s | EVAL   0.7s | TRAIN/TEST acc 0.99/0.69 |\n",
      "                    ---------------------------------------------------------\n",
      "baby                 train/test 87973/20000 total vocab 52\n",
      "                    ---------------------------------------------------------\n",
      "           Logistic | TRAIN   1.9s | EVAL   0.0s | TRAIN/TEST acc 0.85/0.81 |\n",
      "    Logistic C=1000 | TRAIN   1.9s | EVAL   0.0s | TRAIN/TEST acc 0.87/0.79 |\n",
      "    RandomForest 10 | TRAIN  84.7s | EVAL   0.7s | TRAIN/TEST acc 0.90/0.79 |\n",
      "                    ---------------------------------------------------------\n",
      "newsgroup20          train/test 11314/7532 total vocab 282099\n",
      "                    ---------------------------------------------------------\n",
      "    Logistic C=1000 | TRAIN 106.2s | EVAL   0.3s | TRAIN/TEST acc 0.97/0.64 |\n",
      "           Logistic | TRAIN  55.3s | EVAL   0.4s | TRAIN/TEST acc 0.69/0.55 |\n",
      "    RandomForest 10 | TRAIN   2.5s | EVAL   0.7s | TRAIN/TEST acc 0.97/0.47 |\n",
      "                    ---------------------------------------------------------\n",
      "reuters              train/test 7769/3019 total vocab 70000\n",
      "                    ---------------------------------------------------------\n",
      "    Logistic C=1000 | TRAIN 224.7s | EVAL   1.5s | TRAIN/TEST acc 0.99/0.78 |\n",
      "    RandomForest 10 | TRAIN  28.6s | EVAL  29.7s | TRAIN/TEST acc 0.95/0.65 |\n",
      "           Logistic | TRAIN 105.3s | EVAL   1.5s | TRAIN/TEST acc 0.64/0.63 |\n",
      "                    ---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for dataset in list_of_datasets:\n",
    "    dataset[\"X_train_vec\"], dataset[\"X_test_vec\"] = vectorize(HashingVectorizer(n_features = 50000, analyzer=\"char_wb\", ngram_range=[2,5]), \n",
    "                                                              dataset[\"X_train\"], dataset[\"X_test\"])\n",
    "\n",
    "models_eval(list_of_models, list_of_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training word embeddings\n",
    "\n",
    "In 2015-2017 the internet was infatuated with word embeddings. These little embeddings were able to get the \"meaning\" of words, and they could find [related vegetables and pokemon](https://fasttext.cc/docs/en/unsupervised-tutorial.html#nearest-neighbor-queries) for you.\n",
    "\n",
    "Word embeddings are vectors assigned to words, meaning that each word is \"embedded\" in an n-dimensional space. These embedding spaces can have many dimensions, like 100 to 300. Embedding models organize this space by placing similar words close together: the model decides what words are similar by what other words they co-occur with. For example, if bacon and ham are often mentionned alongside pork, breakfast, and greasy, they are related. This is how word embedding models know how to find related words for you.\n",
    "\n",
    "Ultimately, these word embeddings give a slight edge to classification models. First, they're in n-dimensional space, where n is 100-300 not 50,000 to 100,000 (total size of vocabulary). This saves resources. Second, models can know beforehand treat ham and bacon similarly.\n",
    "\n",
    "Word embeddings will work alright with our models, but they won't beat our td-idf champion.\n",
    "\n",
    "### Embedding our datasets\n",
    "\n",
    "We can train the vectors easily with the gensim library. There's a little pre-processing involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase text and remove all non-letters with single spaces\n",
    "def preprocessor(x):\n",
    "    return re.sub(r\"[ ]+\", \" \", re.sub(r\"[^\\w]+\", \" \", x)).lower()\n",
    "\n",
    "# Either split words or characters into list items (tokenize)\n",
    "def w2v_prepare(dataset, by_words=True):\n",
    "    if by_words:\n",
    "        return [preprocessor(line).split() for line in dataset]\n",
    "    else:\n",
    "        return [list(line) for line in dataset]\n",
    "\n",
    "# With the tokenized text, run word2vec on it. Afterwards, delete the model and keep the vectors.\n",
    "def w2v_fit(text, size=100, alpha=0.025, window=5, min_count=5, workers=4, iter=5):\n",
    "    w2v_model = Word2Vec(text, size=size, alpha=alpha, window=window, min_count=min_count, workers=workers)\n",
    "    word_vectors = w2v_model.wv\n",
    "    del w2v_model\n",
    "    print(f\"word2vec model has {len(word_vectors.vocab)} words\")\n",
    "    return word_vectors\n",
    "\n",
    "# After the vectors are ready, we embed our datasets, averaging afterwards\n",
    "def w2v_transform(text, word_vectors):\n",
    "    vocab = set(word_vectors.vocab)\n",
    "    size = word_vectors.vector_size\n",
    "    vectorized = []\n",
    "    for line in text:\n",
    "        line = list(filter(lambda x: x in vocab, line))\n",
    "        if line:\n",
    "            line = np.mean(list(map(lambda x: word_vectors[x], line)), axis=0)\n",
    "            vectorized.append(line)\n",
    "        else:\n",
    "            vectorized.append(np.zeros(size))\n",
    "    return np.array(vectorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our corpora won't be great for word2vec since they're fairly small. This will hurt the quality of the vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2vec model has 101675 words\n",
      "word2vec model has 52 words\n",
      "word2vec model has 26319 words\n"
     ]
    }
   ],
   "source": [
    "ng_wv = w2v_fit(w2v_prepare(ng_data[\"X_train\"]), min_count=1, iter=50, alpha=0.05)\n",
    "baby_wv = w2v_fit(w2v_prepare(baby_data[\"X_train\"], by_words=False), size=20)\n",
    "reuters_wv = w2v_fit(w2v_prepare(reuters_data[\"X_train\"]), min_count=1, iter=50, alpha=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can query word vectors to get related words. Below I look up \"man\" in the newsgroup20 embeddings. The matches are reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('woman', 0.7636096477508545),\n",
       " ('person', 0.6785249710083008),\n",
       " ('child', 0.6541754007339478),\n",
       " ('jesus', 0.6385825276374817),\n",
       " ('father', 0.6232447624206543),\n",
       " ('god', 0.6104214787483215),\n",
       " ('mother', 0.6048308610916138),\n",
       " ('christ', 0.5973607301712036),\n",
       " ('teacher', 0.595134973526001),\n",
       " ('lord', 0.5933548212051392)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ng_wv.most_similar(positive=[\"man\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has to be embedded to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng_data[\"X_train_wv\"] = w2v_transform(w2v_prepare(ng_data[\"X_train\"]), ng_wv)\n",
    "ng_data[\"X_test_wv\"] = w2v_transform(w2v_prepare(ng_data[\"X_test\"]), ng_wv)\n",
    "\n",
    "baby_data[\"X_train_wv\"] = w2v_transform(w2v_prepare(baby_data[\"X_train\"], by_words=False), baby_wv)\n",
    "baby_data[\"X_test_wv\"] = w2v_transform(w2v_prepare(baby_data[\"X_test\"], by_words=False), baby_wv)\n",
    "\n",
    "reuters_data[\"X_train_wv\"] = w2v_transform(w2v_prepare(reuters_data[\"X_train\"]), reuters_wv)\n",
    "reuters_data[\"X_test_wv\"] = w2v_transform(w2v_prepare(reuters_data[\"X_test\"]), reuters_wv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we now have \"denser\" data (100 dimensions instead of 25,000), I'll try out KNN since it won't take forever anymore (but it will still take a long time). KNN does surprisingly work suprisingly well on the babies and reuters datasets, especially with more neighbors (67% on babies and 74% on reuters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_models = {\"Logistic\" : LogisticRegression(solver=\"lbfgs\", n_jobs = -1), \n",
    "                  \"Logistic C=1000\" : LogisticRegression(solver=\"lbfgs\", n_jobs = -1, C=1000), \n",
    "                  \"RandomForest 10\" : RandomForestClassifier(n_jobs = -1), \n",
    "                  \"RandomForest 100\" : RandomForestClassifier(n_jobs = -1, n_estimators=100), \n",
    "                  \"RandomForest 100/10\" : RandomForestClassifier(n_jobs = -1, n_estimators=100, max_depth=10), \n",
    "                  \"KNN 1\" : KNeighborsClassifier(n_neighbors = 1, n_jobs=-1)\n",
    "                 }\n",
    "\n",
    "list_of_datasets = [ng_data, baby_data, reuters_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newsgroup20          train/test 11314/7532 total vocab 282099\n",
      "                    ---------------------------------------------------------\n",
      "    Logistic C=1000 | TRAIN   8.9s | EVAL   0.0s | TRAIN/TEST acc 0.54/0.47 |\n",
      "           Logistic | TRAIN   9.0s | EVAL   0.0s | TRAIN/TEST acc 0.53/0.47 |\n",
      "RandomForest 100/10 | TRAIN   1.6s | EVAL   0.5s | TRAIN/TEST acc 0.90/0.40 |\n",
      "   RandomForest 100 | TRAIN   2.0s | EVAL   0.5s | TRAIN/TEST acc 0.97/0.40 |\n",
      "              KNN 1 | TRAIN   0.1s | EVAL   4.2s | TRAIN/TEST acc 0.97/0.33 |\n",
      "    RandomForest 10 | TRAIN   0.4s | EVAL   0.3s | TRAIN/TEST acc 0.97/0.31 |\n",
      "                    ---------------------------------------------------------\n",
      "baby                 train/test 87973/20000 total vocab 52\n",
      "                    ---------------------------------------------------------\n",
      "   RandomForest 100 | TRAIN   7.3s | EVAL   1.1s | TRAIN/TEST acc 0.87/0.65 |\n",
      "              KNN 1 | TRAIN   0.1s | EVAL   5.3s | TRAIN/TEST acc 0.90/0.65 |\n",
      "    Logistic C=1000 | TRAIN   0.9s | EVAL   0.0s | TRAIN/TEST acc 0.69/0.65 |\n",
      "           Logistic | TRAIN   0.9s | EVAL   0.0s | TRAIN/TEST acc 0.69/0.65 |\n",
      "    RandomForest 10 | TRAIN   1.0s | EVAL   0.3s | TRAIN/TEST acc 0.86/0.64 |\n",
      "RandomForest 100/10 | TRAIN   4.8s | EVAL   0.7s | TRAIN/TEST acc 0.75/0.64 |\n",
      "                    ---------------------------------------------------------\n",
      "reuters              train/test 7769/3019 total vocab 70000\n",
      "                    ---------------------------------------------------------\n",
      "              KNN 1 | TRAIN   1.5s | EVAL  69.0s | TRAIN/TEST acc 1.00/0.74 |\n",
      "           Logistic | TRAIN  44.4s | EVAL   0.1s | TRAIN/TEST acc 0.72/0.70 |\n",
      "    Logistic C=1000 | TRAIN  53.0s | EVAL   0.1s | TRAIN/TEST acc 0.81/0.68 |\n",
      "   RandomForest 100 | TRAIN  41.2s | EVAL  19.0s | TRAIN/TEST acc 1.00/0.67 |\n",
      "RandomForest 100/10 | TRAIN  41.9s | EVAL  19.2s | TRAIN/TEST acc 0.96/0.67 |\n",
      "    RandomForest 10 | TRAIN  15.7s | EVAL  18.7s | TRAIN/TEST acc 0.93/0.64 |\n",
      "                    ---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "models_eval(list_of_models, list_of_datasets, train_key=\"X_train_wv\", test_key=\"X_test_wv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using large pre-trained embeddings\n",
    "\n",
    "Above we trained our word embedding model on our datasets, but is that a good idea? Are toy datasets for text classification sufficient to model the English language? Remember that word2vec operates on co-occurences and that words can appear in many different contexts. It's tough to infer the meaning of a word from only a few examples.\n",
    "\n",
    "Therefore a common strategy with word embeddings is ti simply use pre-trained embeddings from a massive dataset. Thanks to the size of the source corpus, the word relationships are bound to be more finely detailed.\n",
    "\n",
    "You can get a 3.6GB word vector file from [this blogger](http://mccormickml.com/2016/04/12/googles-pretrained-word2vec-model-in-python/) or this [archived Google Code post](https://code.google.com/archive/p/word2vec/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2vec model has 3000000 words\n"
     ]
    }
   ],
   "source": [
    "googlenews = KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary=True)\n",
    "print(f\"word2vec model has {len(googlenews.vocab)} words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng_data[\"X_train_wv\"] = w2v_transform(w2v_prepare(ng_data[\"X_train\"]), googlenews)\n",
    "ng_data[\"X_test_wv\"] = w2v_transform(w2v_prepare(ng_data[\"X_test\"]), googlenews)\n",
    "\n",
    "reuters_data[\"X_train_wv\"] = w2v_transform(w2v_prepare(reuters_data[\"X_train\"]), googlenews)\n",
    "reuters_data[\"X_test_wv\"] = w2v_transform(w2v_prepare(reuters_data[\"X_test\"]), googlenews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, I'll try the same models as above. I am going to ditch the imdb and babies dataset because they lack actual words. (The imdb data is already coded to integer IDs and the baby names are a character-level task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_models = {\"Logistic\" : LogisticRegression(solver=\"lbfgs\", n_jobs = -1), \n",
    "                  \"Logistic C=1000\" : LogisticRegression(solver=\"lbfgs\", n_jobs = -1, C=1000), \n",
    "                  \"RandomForest 10\" : RandomForestClassifier(n_jobs = -1), \n",
    "                  \"RandomForest 100\" : RandomForestClassifier(n_jobs = -1, n_estimators=100), \n",
    "                  \"RandomForest 100/10\" : RandomForestClassifier(n_jobs = -1, n_estimators=100, max_depth=10), \n",
    "                  \"KNN 1\" : KNeighborsClassifier(n_neighbors = 1, n_jobs=-1)\n",
    "                 }\n",
    "\n",
    "list_of_datasets = [ng_data, reuters_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results below are not the best, but they do beat our previous word embedding results. KNN 5 again performs well on the reuters data (76% with KNN 5--not shown)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "newsgroup20          train/test 11314/7532 total vocab 282099\n",
      "                    ---------------------------------------------------------\n",
      "           Logistic | TRAIN  11.2s | EVAL   0.0s | TRAIN/TEST acc 0.65/0.60 |\n",
      "    Logistic C=1000 | TRAIN  21.8s | EVAL   0.0s | TRAIN/TEST acc 0.75/0.60 |\n",
      "RandomForest 100/10 | TRAIN   2.6s | EVAL   0.5s | TRAIN/TEST acc 0.95/0.50 |\n",
      "   RandomForest 100 | TRAIN   3.2s | EVAL   0.5s | TRAIN/TEST acc 0.97/0.50 |\n",
      "              KNN 1 | TRAIN   0.1s | EVAL  11.4s | TRAIN/TEST acc 0.97/0.44 |\n",
      "    RandomForest 10 | TRAIN   0.5s | EVAL   0.2s | TRAIN/TEST acc 0.97/0.33 |\n",
      "                    ---------------------------------------------------------\n",
      "reuters              train/test 7769/3019 total vocab 70000\n",
      "                    ---------------------------------------------------------\n",
      "              KNN 1 | TRAIN   4.8s | EVAL 228.4s | TRAIN/TEST acc 0.99/0.74 |\n",
      "    Logistic C=1000 | TRAIN  98.8s | EVAL   0.3s | TRAIN/TEST acc 0.94/0.74 |\n",
      "RandomForest 100/10 | TRAIN  67.7s | EVAL  20.4s | TRAIN/TEST acc 0.96/0.64 |\n",
      "           Logistic | TRAIN  70.6s | EVAL   0.3s | TRAIN/TEST acc 0.61/0.64 |\n",
      "   RandomForest 100 | TRAIN  69.2s | EVAL  20.5s | TRAIN/TEST acc 0.99/0.64 |\n",
      "    RandomForest 10 | TRAIN  18.3s | EVAL  18.9s | TRAIN/TEST acc 0.93/0.60 |\n",
      "                    ---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "models_eval(list_of_models, [ng_data, reuters_data], train_key=\"X_train_wv\", test_key=\"X_test_wv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural networks\n",
    "\n",
    "We aren't going to be using deep learning here; instead we're just going to use neural networks to train embeddings on-the-fly. Rather than training twice, first on embeddings and then on classification, the word embeddings will be trained alongside classification.\n",
    "\n",
    "The method we use below is effectively [fasttext](https://fasttext.cc/), a fast barebones classifier. It's pretty fast and tends to meet or beat our best results.\n",
    "\n",
    "keras expects sequences of integers as inputs. These inputs are fed to embedding layers that do similar work to word2vec above: words get embeddings that are useful for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a list of tokens, transform them into ngrams\n",
    "def get_ngrams(x, n=1):\n",
    "    if n==1:\n",
    "        return x\n",
    "    elif len(x) >= n:\n",
    "        return [\"_\".join(x[i:i+n]) for i in range(len(x)-n+1)]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# with an ngram interval, such as [2,5], break a list of tokens into the appropriate ngrams\n",
    "def ngram_iter(x, interval):\n",
    "    y = []\n",
    "    for n in range(interval[0], interval[1]+1):\n",
    "        y += get_ngrams(x, n)\n",
    "    return y\n",
    "\n",
    "# prepare data for keras's embeddings layers\n",
    "# this transforms lists of tokens into\n",
    "def keras_data(train_set, test_set, by_words=True, max_unigrams=50000, ngram_range=[1,1]):\n",
    "    train_set = w2v_prepare(train_set, by_words)\n",
    "    test_set = w2v_prepare(test_set, by_words)\n",
    "    \n",
    "    id2word = [i for line in train_set for i in ngram_iter(line, ngram_range)]\n",
    "    \n",
    "    if max_unigrams > 0:\n",
    "        id2word = Counter(id2word)\n",
    "        id2word = list(id2word.items())\n",
    "        id2word.sort(key=lambda x: -x[1])\n",
    "        id2word = [x[0] for x in id2word[:max_unigrams-2]]\n",
    "        id2word = [\"<PAD>\", \"<NULL>\"] + list(set(id2word))\n",
    "    else:\n",
    "        id2word = [\"<PAD>\", \"<NULL>\"] + list(set(id2word))\n",
    "\n",
    "    word2id = dict()\n",
    "    vocab_size = len(id2word)\n",
    "    print(f\"Size of vocabulary: {vocab_size}\")\n",
    "    for i in range(vocab_size):\n",
    "        word2id[id2word[i]] = i\n",
    "\n",
    "    train_set = [[word2id.get(token, 1) for token in ngram_iter(line, ngram_range)] for line in train_set]\n",
    "    test_set = [[word2id.get(token, 1) for token in ngram_iter(line, ngram_range)] for line in test_set]\n",
    "    \n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Through trial and error I've ended up with the settings below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary: 50000\n",
      "Size of vocabulary: 50000\n",
      "Size of vocabulary: 50000\n"
     ]
    }
   ],
   "source": [
    "ng_data[\"X_train_ids\"], ng_data[\"X_test_ids\"] = keras_data(ng_data[\"X_train\"], ng_data[\"X_test\"], ngram_range=[1,1])\n",
    "baby_data[\"X_train_ids\"], baby_data[\"X_test_ids\"] = keras_data(baby_data[\"X_train\"], baby_data[\"X_test\"], by_words=False, ngram_range=[2,5])\n",
    "reuters_data[\"X_train_ids\"], reuters_data[\"X_test_ids\"] = keras_data(reuters_data[\"X_train\"], reuters_data[\"X_test\"], ngram_range=[1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMDB\n",
    "\n",
    "The imdb dataset is used in keras's example implementation of [fastext](https://github.com/keras-team/keras/blob/master/examples/imdb_fasttext.py). I've tweaked it a bit to give the best results.\n",
    "\n",
    "As you can see, the vector size of the embeddings is only *one* and these feed directly to a *single* sigmoid neuron. Nevertheless the model works quite well. *Always try simpler networks!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/20\n",
      "25000/25000 [==============================] - 1s 54us/step - loss: 0.4950 - acc: 0.7659 - val_loss: 0.3333 - val_acc: 0.8725\n",
      "Epoch 2/20\n",
      "25000/25000 [==============================] - 0s 9us/step - loss: 0.2308 - acc: 0.9177 - val_loss: 0.2969 - val_acc: 0.8780\n",
      "Epoch 3/20\n",
      "25000/25000 [==============================] - 0s 9us/step - loss: 0.1473 - acc: 0.9526 - val_loss: 0.2891 - val_acc: 0.8869\n",
      "Epoch 4/20\n",
      "25000/25000 [==============================] - 0s 9us/step - loss: 0.0986 - acc: 0.9726 - val_loss: 0.3359 - val_acc: 0.8704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f60e1d6aba8>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = sequence.pad_sequences(imdb_data[\"X_train_ids\"], maxlen=400)\n",
    "x_test = sequence.pad_sequences(imdb_data[\"X_test_ids\"], maxlen=400)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(50000, 1, input_length=400))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = Adam(lr=0.1)\n",
    "    \n",
    "model.compile(loss='binary_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(min_delta=0.01, patience=2)\n",
    "\n",
    "model.fit(x_train, imdb_data[\"y_train\"],\n",
    "          batch_size=256,\n",
    "          epochs=20,\n",
    "          callbacks=[early_stop],\n",
    "          validation_data=(x_test, imdb_data[\"y_test\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Newsgroup\n",
    "\n",
    "The newsgroup20 dataset is a bit more complex, so it requires a few more parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11314 samples, validate on 7532 samples\n",
      "Epoch 1/50\n",
      "11314/11314 [==============================] - 1s 84us/step - loss: 2.8141 - acc: 0.1640 - val_loss: 2.5467 - val_acc: 0.2797\n",
      "Epoch 2/50\n",
      "11314/11314 [==============================] - 1s 46us/step - loss: 2.1241 - acc: 0.4684 - val_loss: 1.9837 - val_acc: 0.4968\n",
      "Epoch 3/50\n",
      "11314/11314 [==============================] - 1s 47us/step - loss: 1.5417 - acc: 0.6623 - val_loss: 1.6533 - val_acc: 0.5793\n",
      "Epoch 4/50\n",
      "11314/11314 [==============================] - 1s 47us/step - loss: 1.1699 - acc: 0.7678 - val_loss: 1.4782 - val_acc: 0.6158\n",
      "Epoch 5/50\n",
      "11314/11314 [==============================] - 1s 45us/step - loss: 0.9278 - acc: 0.8177 - val_loss: 1.3758 - val_acc: 0.6235\n",
      "Epoch 6/50\n",
      "11314/11314 [==============================] - 1s 46us/step - loss: 0.7555 - acc: 0.8509 - val_loss: 1.3168 - val_acc: 0.6503\n",
      "Epoch 7/50\n",
      "11314/11314 [==============================] - 1s 46us/step - loss: 0.6277 - acc: 0.8768 - val_loss: 1.2627 - val_acc: 0.6710\n",
      "Epoch 8/50\n",
      "11314/11314 [==============================] - 1s 46us/step - loss: 0.5368 - acc: 0.8973 - val_loss: 1.2784 - val_acc: 0.6573\n",
      "Epoch 9/50\n",
      "11314/11314 [==============================] - 1s 46us/step - loss: 0.4641 - acc: 0.9112 - val_loss: 1.2516 - val_acc: 0.6687\n",
      "Epoch 10/50\n",
      "11314/11314 [==============================] - 1s 47us/step - loss: 0.4061 - acc: 0.9220 - val_loss: 1.2581 - val_acc: 0.6666\n",
      "Epoch 11/50\n",
      "11314/11314 [==============================] - 1s 47us/step - loss: 0.3610 - acc: 0.9319 - val_loss: 1.2626 - val_acc: 0.6738\n",
      "Epoch 12/50\n",
      "11314/11314 [==============================] - 1s 45us/step - loss: 0.3214 - acc: 0.9394 - val_loss: 1.2774 - val_acc: 0.6757\n",
      "Epoch 13/50\n",
      "11314/11314 [==============================] - 1s 46us/step - loss: 0.2896 - acc: 0.9454 - val_loss: 1.2934 - val_acc: 0.6717\n",
      "Epoch 14/50\n",
      "11314/11314 [==============================] - 1s 46us/step - loss: 0.2672 - acc: 0.9480 - val_loss: 1.3158 - val_acc: 0.6662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f60e1b835c0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = sequence.pad_sequences(ng_data[\"X_train_ids\"], maxlen=500)\n",
    "x_test = sequence.pad_sequences(ng_data[\"X_test_ids\"], maxlen=500)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(50000, 32, input_length=500))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(len(ng_train_raw.target_names), activation='softmax'))\n",
    "\n",
    "optimizer = Adam(lr=0.01)\n",
    "    \n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(min_delta=0.01, patience=5)\n",
    "\n",
    "model.fit(x_train, ng_data[\"y_train\"],\n",
    "          batch_size=64,\n",
    "          epochs=50,\n",
    "          callbacks=[early_stop],\n",
    "          validation_data=(x_test, ng_data[\"y_test\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reuters\n",
    "\n",
    "If you run the neural network on Reuters with the softmax function, you'll beat the rest with a score of **82%**.\n",
    "\n",
    "However, this approach makes no sense because we have multi-label problem (one record can have more than one label), not a multi-class problem (one record has only one label). The softmax function outputs probabilities that sum to 1; in the case of accuracy, the highest probability is the chosen label. That score of 82% above just means that the neural network beats the other models with one hand tied behind its back (only being able to predict one class). Why? Most Reuters observations only have one class/label with an average of 1.25 label/obs.\n",
    "\n",
    "Instead, the proper thing to do is use a sigmoid action function at output so that each label is evaluated separately. The sigmoids will output 0 or 1, and one sigmoid doesn't affect the other, unlike the softmax.\n",
    "\n",
    "Even though this approach is the correct one, it makes accuracy kind of meaningless. With sigmoids the accuracy shoots to 99% because the neural networks gets a point each time it predicts 0 correctly: the target labels are pretty sparse so this is pretty easy to do! In fact, if the model only predicts 0s, it does pretty well. We need a better metric.\n",
    "\n",
    "I'm not extremely familiar with precision, recall, and f1, but I think they're the right ones to use. We want to measure around real and predicted positives. [Here is the formula for the f1-score.](https://en.wikipedia.org/wiki/F1_score) Precision goes down whenever a positive label is assigned incorrectly, and recall goes down whenever a true positive label is incorrectly missed. If the model only predicts 0s, its recall score will be zero; if the model only predicts 1s, its precision score will be zero. This sounds good.\n",
    "\n",
    "keras removed its precision, recall, and f1 metrics, so you need to define them yourself. Or, you could just grab [some code on Stack Overflow](https://stackoverflow.com/a/45305384)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the f1-score metric, the model has a test score of about 81%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7769 samples, validate on 3019 samples\n",
      "Epoch 1/10\n",
      "7769/7769 [==============================] - 1s 155us/step - loss: 0.0629 - f1: 0.4250 - val_loss: 0.0305 - val_f1: 0.6660\n",
      "Epoch 2/10\n",
      "7769/7769 [==============================] - 1s 112us/step - loss: 0.0222 - f1: 0.7559 - val_loss: 0.0223 - val_f1: 0.7589\n",
      "Epoch 3/10\n",
      "7769/7769 [==============================] - 1s 113us/step - loss: 0.0117 - f1: 0.8795 - val_loss: 0.0204 - val_f1: 0.7905\n",
      "Epoch 4/10\n",
      "7769/7769 [==============================] - 1s 115us/step - loss: 0.0061 - f1: 0.9406 - val_loss: 0.0228 - val_f1: 0.7830\n",
      "Epoch 5/10\n",
      "7769/7769 [==============================] - 1s 134us/step - loss: 0.0040 - f1: 0.9638 - val_loss: 0.0230 - val_f1: 0.8040\n",
      "Epoch 6/10\n",
      "7769/7769 [==============================] - 1s 115us/step - loss: 0.0028 - f1: 0.9754 - val_loss: 0.0232 - val_f1: 0.8177\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f60e1b4bef0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = sequence.pad_sequences(reuters_data[\"X_train_ids\"], maxlen=500)\n",
    "x_test = sequence.pad_sequences(reuters_data[\"X_test_ids\"], maxlen=500)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(50000, 128, input_length=500))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(90, activation='sigmoid'))\n",
    "\n",
    "optimizer = Adam(lr=0.1)\n",
    "    \n",
    "model.compile(loss='binary_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=[f1])\n",
    "\n",
    "early_stop = EarlyStopping(min_delta=0.1, patience=5)\n",
    "\n",
    "model.fit(x_train, reuters_data[\"y_train\"],\n",
    "          batch_size=64,\n",
    "          epochs=10,\n",
    "          callbacks=[early_stop],\n",
    "          validation_data=(x_test, reuters_data[\"y_test\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I'm paranoid, I want to make sure that the model can indeed predict more than one label. I had to dig around a little to find an observation that looked nice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real\n",
      "[[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]]\n",
      "Predicted\n",
      "[0.999 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " 1.    0.    0.    0.    0.    0.   ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Real\")\n",
    "print(reuters_data[\"y_train\"][6].todense())\n",
    "print(\"Predicted\")\n",
    "print(np.round(model.predict(x_train)[6], decimals=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Babies\n",
    "\n",
    "The results on the baby names is reasonable when using 2 to 5 ngrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 87973 samples, validate on 20000 samples\n",
      "Epoch 1/20\n",
      "87973/87973 [==============================] - 1s 9us/step - loss: 0.6225 - acc: 0.6462 - val_loss: 0.5967 - val_acc: 0.6331\n",
      "Epoch 2/20\n",
      "87973/87973 [==============================] - 1s 6us/step - loss: 0.5020 - acc: 0.7602 - val_loss: 0.5214 - val_acc: 0.7201\n",
      "Epoch 3/20\n",
      "87973/87973 [==============================] - 1s 6us/step - loss: 0.4372 - acc: 0.7987 - val_loss: 0.4842 - val_acc: 0.7552\n",
      "Epoch 4/20\n",
      "87973/87973 [==============================] - 1s 6us/step - loss: 0.4016 - acc: 0.8180 - val_loss: 0.4654 - val_acc: 0.7687\n",
      "Epoch 5/20\n",
      "87973/87973 [==============================] - 1s 6us/step - loss: 0.3766 - acc: 0.8311 - val_loss: 0.4663 - val_acc: 0.7622\n",
      "Epoch 6/20\n",
      "87973/87973 [==============================] - 1s 6us/step - loss: 0.3578 - acc: 0.8414 - val_loss: 0.4417 - val_acc: 0.7873\n",
      "Epoch 7/20\n",
      "87973/87973 [==============================] - 1s 6us/step - loss: 0.3434 - acc: 0.8483 - val_loss: 0.4428 - val_acc: 0.7869\n",
      "Epoch 8/20\n",
      "87973/87973 [==============================] - 1s 6us/step - loss: 0.3313 - acc: 0.8538 - val_loss: 0.4446 - val_acc: 0.7864\n",
      "Epoch 9/20\n",
      "87973/87973 [==============================] - 1s 6us/step - loss: 0.3214 - acc: 0.8580 - val_loss: 0.4426 - val_acc: 0.7909\n",
      "Epoch 10/20\n",
      "87973/87973 [==============================] - 1s 6us/step - loss: 0.3127 - acc: 0.8603 - val_loss: 0.4510 - val_acc: 0.7863\n",
      "Epoch 11/20\n",
      "87973/87973 [==============================] - 1s 6us/step - loss: 0.3051 - acc: 0.8638 - val_loss: 0.4508 - val_acc: 0.7907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6106a96630>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = sequence.pad_sequences(baby_data[\"X_train_ids\"], maxlen=100)\n",
    "x_test = sequence.pad_sequences(baby_data[\"X_test_ids\"], maxlen=100)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(50000, 1, input_length=100))\n",
    "model.add(GlobalAveragePooling1D())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = Adam(lr=0.01)\n",
    "    \n",
    "model.compile(loss='binary_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(min_delta=0.01, patience=5)\n",
    "\n",
    "model.fit(x_train, baby_data[\"y_train\"],\n",
    "          batch_size=256,\n",
    "          epochs=20,\n",
    "          callbacks=[early_stop],\n",
    "          validation_data=(x_test, baby_data[\"y_test\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent neural networks\n",
    "\n",
    "Since the baby names are short sequences, they'll work fine with recurrent neural networks. This is based on the [example from keras](https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary: 54\n",
      "Train on 87973 samples, validate on 20000 samples\n",
      "Epoch 1/10\n",
      "87973/87973 [==============================] - 23s 264us/step - loss: 0.4550 - acc: 0.7849 - val_loss: 0.4502 - val_acc: 0.7936\n",
      "Epoch 2/10\n",
      "87973/87973 [==============================] - 22s 252us/step - loss: 0.4337 - acc: 0.8010 - val_loss: 0.4494 - val_acc: 0.8007\n",
      "Epoch 3/10\n",
      "87973/87973 [==============================] - 22s 251us/step - loss: 0.4356 - acc: 0.7984 - val_loss: 0.4562 - val_acc: 0.7948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6106159a90>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baby_data[\"X_train_ids\"], baby_data[\"X_test_ids\"] = keras_data(baby_data[\"X_train\"], baby_data[\"X_test\"], by_words=False, ngram_range=[1,1])\n",
    "\n",
    "x_train = sequence.pad_sequences(baby_data[\"X_train_ids\"], maxlen=20)\n",
    "x_test = sequence.pad_sequences(baby_data[\"X_test_ids\"], maxlen=20)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(55, 64, input_length=20))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = Adam(lr=0.01)\n",
    "    \n",
    "model.compile(loss='binary_crossentropy',\n",
    "    optimizer=optimizer,\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(min_delta=0.01, patience=2)\n",
    "\n",
    "model.fit(x_train, baby_data[\"y_train\"],\n",
    "          batch_size=64,\n",
    "          epochs=10,\n",
    "          callbacks=[early_stop],\n",
    "          validation_data=(x_test, baby_data[\"y_test\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run predictions on names to see how well the model does. A 1 is a predicted male name, 0 is female."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary: 54\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.8543145],\n",
       "       [0.6411952],\n",
       "       [0.1644226],\n",
       "       [0.5717714],\n",
       "       [0.283032 ]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_baby = [\"john\", \"mary\", \"gimli\", \"frodo\", \"pikachu\"]\n",
    "\n",
    "_, test_baby_ids = keras_data(baby_data[\"X_train\"], test_baby, by_words=False, ngram_range=[1,1])\n",
    "\n",
    "test_baby_ids = sequence.pad_sequences(test_baby_ids, maxlen=20)\n",
    "\n",
    "model.predict(test_baby_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
